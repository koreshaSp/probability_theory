% 2023.04.18 lecture 10
\documentclass[../main.tex]{subfiles}
\begin{document}

\newpage
\section{Оценки больших уклонений.}

Закон больших чисел в форме Чебышева (следствие \ref{corallry:law_of_large_numbers_chebyshev}) позволяет оценить степень уклонения среднего значения случайных величин от ожидаемого. Если есть независимые одинаково распределённые случайные величины $ \xi_1, \xi_2, \ldots $ с матожиданием $ \mu = \E\xi_1 $ и конечной дисперсией $ \sigma^{2}=\D\xi_1 $, то
\begin{align*}
 \lim_{n \to \infty} P\left[\left|\frac{S_n}{n}  - \mu \right| \geqslant \eps\right] = 0.
\end{align*} Более того, мы явно вывели оценку
\begin{align}
 \label{eq:small_variance_law_of_large_numbers_chebyshev}
 P \left[ \left| \frac{S_n}{n}-\mu \right| \geqslant \eps \right] \leqslant \frac{\sigma^{2}}{n\eps}.
\end{align}

Пусть теперь поставлена другая задача: мы хотим оценить сверху вероятность \textit{большого уклонения}, то есть вероятность
\begin{align*}
 P \left[ \frac{S_n}{n} \geqslant r \right],
\end{align*} где $ r > \mu $. Предыдущая оценка \eqref{eq:small_variance_law_of_large_numbers_chebyshev} годится, если дисперсия конечная. Но оказывается, можно сделать гораздо лучше.

\subsection{Неравенство Чернова.}

\begin{df}
 Случайная величина $ \xi $ \textit{удовлетворяет условию Крамера} при $ \lambda_0 $, если при всех $ \lambda \in (0,\lambda_0) $
 \begin{align*}
  \E e^{\lambda\xi} < +\infty.
 \end{align*}
\end{df}

Для случайных величин, удовлетворяющих условию Крамера, мы можем написать гораздо лучшую оценку большого уклонения.

\begin{prop}[неравенство Чернова]
 \label{proposition:chernoff_bound}
 Пусть $ \xi_1,\xi_2, \ldots $ --- независимые одинаково распределённые случайные величины, удовлетворяющие условию Крамера при $ \lambda_0 > 0 $. Тогда для всякого $ r \in \R $ выполнено \emph{неравенство Чернова:}
 \begin{align}
  \label{eq:chernoff_bound}
  P \left[ \frac{S_n}{n} \geqslant r \right] \leqslant \exp \left[ -n \cdot I(r) \right],
 \end{align} где
 \begin{align*}
  I(r) = \sup_{0 < \lambda < \lambda_0} \left\{ \lambda r - \log \E e^{\lambda\xi_1} \right\}\text{ --- \emph{функция уклонения}.}
 \end{align*}
\end{prop}

Неравенство Чернова \eqref{eq:chernoff_bound} для фиксированного $ r $ даёт экспоненциально малую оценку порядка $ \OO(e^{-cn}) $, в то время как оценка \eqref{eq:small_variance_law_of_large_numbers_chebyshev} из закона больших чисел в форме Чебышева даёт лишь оценку порядка $ \OO(1 / n) $.

\begin{proof}[\normalfont\textsc{Доказательство предложения \ref{proposition:chernoff_bound}}]
 \begin{align*}
  P \left[ \frac{S_n}{n} \geqslant r \right] = P(S_n \geqslant nr) = P(\lambda S_n \geqslant \lambda n r) = P(e^{\lambda S_n} \geqslant e^{\lambda n r})
 \end{align*} при всяком $ \lambda > 0 $. По неравенству Маркова \eqref{equation:markov_inequality} и по независимости
 \begin{align*}
  P \left[ \frac{S_n}{n} \geqslant r \right] \leqslant \frac{\E e^{\lambda S_n}}{e^{\lambda n r}} = \left( \frac{\E e^{\lambda \xi_1}}{e^{\lambda r}} \right)^{n} = \exp \left[ -n \cdot (\lambda r - \log \E e^{\lambda\xi_1}) \right].
 \end{align*} Так как это верно при любом $ \lambda \in (0,\lambda_0) $, то
 \begin{align*}
  P \left[ \frac{S_n}{n} \geqslant r \right] \leqslant \exp \left[ -n \cdot I(r) \right].
 \end{align*}
\end{proof}

\subsection{Примеры функций уклонения.}

Вычислим функции уклонения некоторых конкретных распределений.

\begin{exmpl}[неравенство Чернова для стандартного нормального распределения]
 Пусть $ \xi \sim \Norm(0, 1) $ имеет стандартное нормальное распределение. Заметим, что $ \xi $  удовлетворяет условию Крамера при $ \lambda_0 = +\infty $: для любого $ \lambda > 0 $
 \begin{align*}
  \E e^{\lambda \xi} = \frac{1}{\sqrt{2\pi}} \int_{\R} e^{\lambda x}  e^{-x^{2} / 2}\,dx = \frac{1}{\sqrt{2\pi}} \int_{\R} e^{-(x-\lambda)^{2} / 2}\,dx \cdot e^{\lambda^{2} / 2} = e^{\lambda^{2} / 2}.
 \end{align*} Тогда для фиксированного $ r\in\R $ у функции
 \begin{align*}
  \varphi(\lambda) = \lambda r - \log \E e^{\lambda \xi}  = \lambda r - \frac{\lambda^{2}}{2}
 \end{align*} при $ r > 0 $ максимум будет в точке $ \lambda = r $, и равен  $ r^{2}  / 2$. То есть, функция уклонения равна
 \begin{align*}
  I(r) = \frac{r^{2}}{2}, \qquad r > 0.
 \end{align*} Тогда по неравенству Чернова \eqref{eq:chernoff_bound}
 \begin{align*}
  P \left[ \frac{S_n}{n} \geqslant r \right] \leqslant e^{-nr^{2} / 2}
 \end{align*} при $ r > 0 $.
\end{exmpl}

\begin{exmpl}[неравенство Чернова для стандартного экспоненциального распределения]
 Пусть $ \xi \sim \Exp(1) $ имеет стандартное экспоненциальное распределение. $ \xi $ удовлетворяет условию Крамера при  $ \lambda_0 = 1 $:
 \begin{align*}
  \E e^{\lambda \xi} = \int_{0}^{\infty} e^{\lambda x}e^{-x}\,dx = \int_{0}^{\infty} e^{-(1 - \lambda)x}\,dx = \left. \frac{e^{-(1-\lambda)x}}{-(1-\lambda)} \right|_0^{\infty} = \frac{1}{1 - \lambda}
  \end{align*} для всех $ \lambda \in (0,1) $. Далее,
  \begin{align*}
   \varphi(\lambda) = \lambda r - \log \E e^{\lambda \xi} = \lambda r + \log(1 - \lambda).
  \end{align*} Максимизируем функцию $ \varphi(\lambda) $. Продифференцируем:
  \begin{align*}
   (\lambda r + \log(1 - \lambda))' = r - \frac{1}{1 - \lambda} = 0 \iff 1 - \lambda = \frac{1}{r} \iff \lambda = 1 - \frac{1}{r}.
  \end{align*} Это верно при $ r > 1 $. Тогда функция уклонения равна
  \begin{align*}
   I(r) = \left(1 - \frac{1}{r}\right)r + \log \frac{1}r = r - 1 - \log r.
  \end{align*} Тогда по неравенству Чернова \eqref{eq:chernoff_bound}:
  \begin{align*}
   P \left[ \frac{S_n}{n} \geqslant r \right] \leqslant e^{-n(r - 1 - \log r)}.
  \end{align*}
 \end{exmpl}

 \begin{exercs*}
  Проделать то же самое для бернуллиевской случайной величины.
 \end{exercs*}

 Такого сорта оценки часто возникают во всяких вероятностных алгоритмах.

 \newpage

 \part{Дискретные случайные процессы.}

 \section{Условное математическое ожидание.}

 \subsection{УМО относительно события.}

 \begin{df}[условное математическое ожидание относительно события]
  Пусть $ \xi $  --- случайная величина, $ A \in \F $  --- событие, $ P(A) > 0 $. Тогда \textit{математическим ожиданием $ \xi $ при условии события $ A $} называется число
  \begin{align*}
   \E(\xi \mid A) = \frac{\E (\xi \cdot \Ind_A)}{P(A)}.
  \end{align*}
 \end{df}

 Это определение элементарно и полностью аналогично определению условной вероятности: по сути мы <<сужаем>> вероятностное пространство $ \Omega $ на событие $ A $. Вместе с вероятностным пространством сужается также пространство событий ($ \sigma $-алгебра), мера, и всевозможные случайные величины (почти наверняка меняя своё распределение).

 В более элементарном курсе теории вероятностей мы бы ограничились этим определением, и тогда мы бы смогли определить условное математическое ожидание одной случайной величины относительно другой случайной величины, но только в том случае, когда вторая случайная величина дискретна. Так как нам этого недостаточно, мы введём другое, более фундаментальное определение условного математического ожидания.

 \subsection{УМО относительно \texorpdfstring{$\sigma$}{sigma}-алгебры.}

 \begin{df}[условное математическое ожидание относительно $ \sigma $-алгебры]
  \label{df:umo}
  Пусть $ (\Omega, \F, P) $ --- вероятностное пространство, $ \xi \colon \, \Omega \to \R $ --- случайная величина. Пусть $ \mathfrak A \subset \F $ --- некоторая $ \sigma $-алгебра. Тогда \textit{математическим ожиданием $ \xi $ относительно $ \sigma $-алгебры $ \A $} называется случайная величина $ \eta $ (которую обозначают $ \E(\xi \mid \A) = \eta $), обладающая следующими двумя свойствами.
  \begin{enumerate}
   \item $ \eta $ измерима относительно $ \sigma $-алгебры $ \mathfrak A $.
   \item Для любого измеримого множества $ A \in \A $ выполнено
    \begin{align}
     \label{eq:def:umo}
     \E(\xi \cdot \Ind_A) = \E(\eta \cdot \Ind_A).
    \end{align}
  \end{enumerate}
 \end{df}

 \begin{remrk*}
  Так как $ \A \subset \F $, то любая функция, измеримая относительно $ \A $, автоматически измерима относительно $ \F $, поэтому функция $ \eta $, удовлетворяющая определению \ref{df:umo}, действительно является случайной величиной.
 \end{remrk*}

 Неформально, мы ищем случайную величину $ \eta $, измеримую относительно $ \A $, которая <<наилучшим образом>> приближает $ \xi $.

 Равенство \eqref{eq:def:umo} можно также записать в виде
 \begin{align*}
  \E(\xi \mid A) = \E(\eta \mid A).
 \end{align*}

 Так как в определении не дана явная формула для условного матожидания, то встаёт вопрос о его существовании и единственности. Однако, если у величины $ \xi $ есть математическое ожидание, то в этом случае есть как существование, так и единственность.

 \begin{thm}[существование и единственность УМО относительно $ \sigma $-алгебры]
  Пусть $ \A \subset \F $ --- $ \sigma $-алгебра, и пусть случайная величина $ \xi $ имеет математическое ожидание: $ \E \left| \xi \right| < +\infty $. Тогда условное математическое ожидание $ \E(\xi\mid\A) $ существует и единственно с точностью до совпадения почти всюду.
 \end{thm}
 \begin{proof}[\normalfont\textsc{Доказательство}]\

  Существование. Рассмотрим две неотрицательные случайные величины $ \xi_\pm = \max(\pm \xi, 0) $. Рассмотрим также следующие две меры в измеримом пространстве $ (\Omega,\A)$:
  \begin{align*}
   \mu_\pm (A) = \E \left( \xi_\pm \cdot \Ind_A \right) = \int_{A} \xi_\pm \,dP. 
  \end{align*} Меры $ \mu_\pm $ абсолютно непрерывны относительно $ P $ (то есть $ P(A) = 0 $ влечёт $ \mu_\pm(A) = 0 $) в измеримом пространстве $ (\Omega,\A) $. По теореме Радона-Никодима существует такие две неотрицательные функции $ \eta_\pm \colon\, \Omega \to [0, +\infty)  $, измеримые относительно $ \A $, что
  \begin{align*}
   \mu_\pm (A) = \int_{A} \eta_\pm \, dP = \E (\eta_\pm \cdot \Ind_A).
  \end{align*} Тогда случайная величина $ \eta = \eta_+ - \eta_- $ как раз подходит.

  Единственность. Пусть $ \eta $ и $ \tilde \eta $ --- пара условных матожиданий. Тогда
  разность $ \eta - \tilde \eta $ измерима относительно $ \sigma $-алгебры $ \A $, и $ \E((\eta-\tilde\eta) \Ind_A) = 0 $ для любого $ A \in \A $. Из этого следует $ \eta - \tilde\eta = 0 $ почти всюду: нужно рассмотреть множества
  \begin{align*}
   A_+ &= \left\{ \eta - \tilde\eta > 0 \right\} \in \A, \\
   A_- &= \left\{ \eta - \tilde\eta < 0 \right\} \in \A,
  \end{align*} и показать, что их меры равны нулю.
 \end{proof}

 \begin{prop}[свойства УМО относительно $ \sigma $-алгебры]\
  \begin{enumerate}
   \item \label{umo_property_1} Если $ \xi $ измерима относительно $ \A $, то $ \E(\xi \mid \A) = \xi $ почти всюду.
   \item \label{umo_property_2} $ \E(\xi\mid \left\{ \varnothing,\Omega \right\}) = \E \xi $ --- константа.
   \item \label{umo_property_3} Пусть $ \A_1 \subset \A_2 \subset \F $. Тогда
    \begin{align*}
     \E(\E(\xi \mid \A_2) \mid \A_1) = \E(\xi \mid \A_1).
    \end{align*}
   \item \label{umo_property_4} $ \E(\E(\xi \mid \A)) = \E \xi $.
   \item \label{umo_property_5} $ \E(\xi \mid \A) $ линейно по $ \xi $:
    \begin{align*}
     \E(a \cdot \xi_1 + b \cdot \xi_2 \mid \A) = a \cdot\E(\xi_1 \mid \A) + b\cdot\E(\xi_2 \mid \A).
    \end{align*}
   \item \label{umo_property_6} Если $ \xi \leqslant \eta $ почти всюду, то и $ \E(\xi \mid \A) \leqslant \E(\eta \mid \A) $ почти всюду.
  \end{enumerate}
 \end{prop}
 \begin{proof}[\normalfont\textsc{Доказательство}]\
  \begin{enumerate}
   \item Очевидно: можно взять $ \xi $ в качестве $ \eta $.
   \item Случайная величина $ \eta $ измерима относительно $ \sigma $-алгебры $ \left\{ \varnothing, \Omega \right\} $ тогда и только тогда, когда $ \eta \equiv \mathrm{const} $. Таким образом, нас интересует такая константа $ c $, что
    \begin{align*}
     c = \E(c \Ind_\Omega) = \E(\xi \Ind_\Omega) = \E\xi.
    \end{align*}
   \item Обозначим $ \eta = \E(\xi \mid \A_2) $ и $ \zeta = \E(\xi \mid \A_1) $. Нужно доказать, что $ \zeta = \E(\eta \mid \A_1) $, то есть $ \zeta $ измерима относительно $ \A_1 $, и $ \E(\zeta\Ind_A) = \E(\eta\Ind_A) $ для любого $ A \in \A_1 $. Измеримость относительно $ \A_1 $ есть по построению $ \zeta $. Возьмём любое множество $ A \in \A_1 $. Тогда $ A \in \A_2 $, и поэтому есть равенство
    \begin{align*}
     \E(\eta \Ind_A) = \E(\xi\Ind_A) = \E(\zeta \Ind_A).
    \end{align*}

   \item Воспользуемся пунктами \ref{umo_property_2} и \ref{umo_property_3}:
    \begin{align*}
     \E\xi = \E(\xi \mid \{\varnothing, \Omega\}) = \E(\E(\xi \mid \F) \mid \{\varnothing, \Omega\}) = \E(\E(\xi \mid \F)),
    \end{align*} где $ \F $ --- исходная $ \sigma $-алгебра, относительно которой измерима $ \xi $.
   \item Возьмём $\eta_1 = \E(\xi_1 \mid \A), \ \eta_2 = \E(\xi_2 \mid \A)$. Тогда
    \begin{align*}
     \E((a \cdot \xi_1 + b \cdot \xi_2) \Ind_A) &= a \cdot \E(\xi_1 \Ind_A) + b \cdot \E(\xi_2 \Ind_A) \\
     &= a \cdot \E(\eta_1 \Ind_A) + b \cdot \E(\eta_2 \Ind_A) \\
     &= \E((a \cdot \eta_1 + b \cdot \eta_2) \Ind_A).
    \end{align*}
    Поскольку случайная величина $ a \cdot \eta_ 1 + b \cdot \eta_2 $ измерима относительно $ \A $, получаем
    \begin{align*}
     a \cdot \eta_1 + b \cdot \eta_2 = \E(a \cdot \xi_1 + b \cdot \xi_2 \mid \A).
    \end{align*}
   \item По линейности (пункт \ref{umo_property_5}) достаточно проверить, что если $ \xi \geqslant 0 $, то $ \E(\xi \mid \A) \geqslant 0 $ почти всюду. Обозначим $ \eta = \E(\xi \mid \A) $. Рассмотрим множество $ A_- = \left\{ \eta < 0 \right\} \in \A $. Тогда 
    \begin{align*}
     0\geqslant \E(\eta \Ind_{A_-}) = \E(\xi\Ind_{A_-}) \geqslant 0.
    \end{align*} Поэтому $ \E(\eta \Ind_{A_-}) = 0 $, и множество $ A_- $ имеет нулевую меру.
  \end{enumerate}
 \end{proof}

 \begin{thm}
  Пусть $ \xi $ и $ \eta $ --- случайные величины. Если $ \eta $ измерима относительно $ \sigma $-алгебры $ \A $, то
  \begin{align*}
   \E(\xi\eta \mid\A) = \eta \cdot \E(\xi \mid \A).
  \end{align*}
 \end{thm}
 \begin{proof}[\normalfont\textsc{Доказательство}]
  Проверять будем по стандартной схеме из теории меры.
  \begin{itemize}
   \item Проверим сначала для индикаторов $ \eta = \Ind_B $, $ B \in \A $. Мы хотим проверить
    \begin{align*}
     \E(\xi\cdot\Ind_B \mid \A) = \Ind_B \cdot \E(\xi \mid \A),
    \end{align*} то есть, что правая часть подходит под определение условного математического ожидания. Она, очевидно, измерима относительно $ \A $, поэтому нужно лишь проверить
    \begin{align*}
     \E(\Ind_B \cdot \E(\xi\mid\A) \cdot \Ind_A) = \E(\xi\cdot\Ind_B\cdot\Ind_A)
    \end{align*} для любого $ A\in\A $. Правая часть равна $ \E(\xi\cdot\Ind_{A \cap B}) $, а левая часть равна $ \E(\E(\xi \mid \A)\cdot\Ind_{A\cap B}) $. Однако по определению условного математического ожидания есть равенство
    \begin{align*}
     \E(\E(\xi \mid \A)\cdot\Ind_{A\cap B}) = \E(\xi\cdot\Ind_{A\cap B}),
    \end{align*} ведь $ A \cap B \in \A $.
   \item По линейности теорема верна для всех простых неотрицательных $ \eta $.
   \item По теореме об аппроксимации и теореме Леви теорема верна для неотрицательных измеримых $ \eta $.
   \item Для функций произвольного знака рассмотреть $ \eta_\pm  =\max(\pm \eta, 0) $.
  \end{itemize}
 \end{proof}

 По аналогии с условным математическим ожиданием, мы можем определить условную вероятность (но уже относительно $ \sigma $-алгебры).

 \begin{df}[условная вероятность относительно $ \sigma $-алгебры]
  \textit{Условной вероятностью события $ A \in \F $ относительно $ \sigma $-алгебры $ \A $} называется случайная величина
  \begin{align*}
   P(B \mid \A) = \E(\Ind_B \mid \A).
  \end{align*}
 \end{df}

 \subsection{УМО относительно случайной величины.}

 Мы определили условное математическое ожидание относительно $ \sigma $-алгебры, а хотим построить определение относительно случайной величины. Значит, нам нужно научится естественным образом строить $ \sigma $-алгебру по данной случайной величине, что приводит нас к следующему определению.

 \begin{df}[$ \sigma $-алгебра, порождённая случайной величиной]
  \textit{$ \sigma $-алгеброй, порождённой} случайной величиной $ \eta $ называется наименьшая $ \sigma $-алгебра $ \sigma(\eta) $, относительно которой $ \eta $ измерима.
 \end{df}
 \begin{prop}
  Для любой случайной величины $ \eta $, $ \sigma $-алгебра, порождённая $ \eta $ существует, причём
  \begin{align*}
   \sigma(\eta) = \left\{ \left\{ \eta \in B \right\} \mid B \in \B_1 \right\}.
  \end{align*}
 \end{prop}
 \begin{proof}[\normalfont\textsc{Доказательство}]
  Так как прообраз всякого борелевского множества измерим при измеримой функции, то в $ \sigma $-алгебру $ \sigma(\eta) $ обязаны попасть множества вида $ \eta^{-1}(B) = \left\{ \eta \in B \right\} $, $ B \in \B_1 $. С другой стороны, семейство таких множеств уже образует $ \sigma $-алгебру.
  \begin{itemize}
   \item $ \varnothing = \eta^{-1}(\varnothing) $, и $ \Omega = \eta^{-1}(\R) $.
   \item Если $ A_1 = \eta^{-1}(B_1),\; A_2 = \eta^{-1}(B_2), \ldots $, то
    \begin{align*}
     \bigcup_{k=1}^{\infty} A_k = \eta^{-1} \left( \bigcup_{k=1}^{\infty} B_k \right).
    \end{align*}
   \item Если $ A = \eta^{-1}(B) $, то $ \Omega \setminus A = \eta^{-1}(\R \setminus B) $.
  \end{itemize}
 \end{proof}

 Естественным образом определим УМО относительно случайной величины как УМО относительно порождённой ей $ \sigma $-алгеброй.

 \begin{df}[условное математическое ожидание относительно случайной величины]
  Пусть $ \xi $ и $ \eta $ --- случайные величины. \textit{Условным математическим ожиданием $ \xi $ относительно $ \eta $} называется случайная величина
  \begin{align*}
   \E(\xi \mid \eta) := \E (\xi \mid \sigma(\eta)).
  \end{align*} 
 \end{df}
 \begin{thm}
  Если случайные величины $ \xi $ и $ \eta $ независимы, то
  \begin{align*}
   \E(\xi \mid \eta) = \E\xi.
  \end{align*}
 \end{thm}
 \begin{proof}[\normalfont\textsc{Доказательство}]
  Нужно проверить, что для всякого $ A \in \sigma(\eta) $
  \begin{align*}
   \E(\xi\Ind_A) = \E((\E\xi)\Ind_A) = \E\xi \cdot \E \Ind_A.
  \end{align*} Таким образом, нужно показать независимость случайных величин $ \xi $  и $ \Ind_A $. Так как индикатор принимает лишь значения $ 0 $ и $ 1 $, то достаточно показать независимость событий $ \left\{ \xi \in C \right\} $ и $ \left\{ \Ind_A = 1 \right\} = A  = \left\{ \eta \in B \right\}$. А она есть, ведь $ \xi $ и $ \eta $ независимы.
 \end{proof}

 \subsection{УМО относительно разбиения.}

 \begin{exmpl}
  \label{example:umo_otn_partition}
  Пусть есть разбиение всего вероятностного пространства на счётное число событий:
  \begin{align*}
   \Omega = \bigsqcup_{n=1}^{\infty} A_n, \qquad A_n \in \F.
  \end{align*} Натянем на разбиение $ \left\{A_n \right\}_{n=1}^{\infty} $ $ \sigma $-алгебру $ \A $:
  \begin{align*}
   \A = \left\{ \bigsqcup_{n \in I} A_n \Mid I \subset \N \right\}.
  \end{align*} 

  Найдём условное математическое ожидание $ \xi $ относительно такой $ \sigma $-алгебры $ \A $. Так как оно измеримо относительно $ \A $, то
  \begin{align*}
   \eta = \E(\xi \mid \A) = \sum_{n=1}^{\infty} c_n \Ind_{A_n}.
   \end{align*} Нам будет достаточно равенства \begin{align*}
   \E(\eta\cdot\Ind_{A_n}) = \E(\xi\cdot\Ind_{A_n}), \qquad n \geqslant 1,
  \end{align*} для остальных множеств $ B \in \A $ равенство получится по линейности. Левая часть равна $ c_n \cdot \E \Ind_{A_n} $, поэтому
  \begin{align*}
   c_n = \frac{\E(\xi \cdot \Ind_{A_n})}{P(A_n)} = \E(\xi \mid A_n).
  \end{align*} Таким образом, условное математическое ожидание относительно такой $ \sigma $-алгебры равно
  \begin{align*}
   \E(\xi \mid \A) = \sum_{n=1}^{\infty} \E(\xi\mid A_n)  \cdot \Ind_{A_n}.
  \end{align*}
 \end{exmpl}

 \begin{remrk}
  Пусть случайная величина $ \eta \colon\,\Omega \to \left\{ y_1, y_2, y_3, \ldots \right\} $ дискретна. Тогда $ \sigma(\eta) $ --- это $ \sigma $-алгебра, натянутая на счётное число событий вида $ A_n = \left\{ \eta = y_n \right\} $, то есть она имеет вид из примера \ref{example:umo_otn_partition}. Поэтому, условное матожидание $ \xi $ относительно $ \eta $ выражается как
  \begin{align*}
   \E(\xi \mid \eta) = \sum_{n=1}^{\infty} \E(\xi \mid \eta = y_n) \cdot \Ind_{\left\{ \eta = y_n \right\}}.
  \end{align*}

  В этом случае условное матожидание $ \E(\xi \mid \eta) $ называют \textit{условным матожиданием $ \xi $ относительно разбиения}.
 \end{remrk}
 \end{document}
