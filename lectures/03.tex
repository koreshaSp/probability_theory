% 2023.02.28: lecture 03
\documentclass[../main.tex]{subfiles}
\begin{document}

\subsection{Примеры применения предельных теорем.}

\begin{exmpl}[задача о театре]
 Есть театр с двумя входами. В театре $n=1600$ мест. У каждого входа есть гардероб. Зрители заходят через один из входов, выбирая случайный из двух, и идут оставлять вещи в соответствующий гардероб. В каждом гардеробе помимо необходимых $ n / 2 = 800 $ мест мы можем добавить несколько дополнительных мест. Мы хотим добавить как можно меньше дополнительных мест, чтобы хотя бы один из гардеробов переполнятся не чаще, чем раз в месяц. 

 Здесь имеется схема Бернулли с $p = \frac{1}{2}$. Пусть $C \geqslant 0$ --- это сколько дополнительных мест (поверх необходимых $800$) мы предоставили в каждый из гардеробов. Оба гардероба не переполнятся, если и только если выполнено неравенство $800 - C \leqslant S_n \leqslant 800 + C$. Значит, задача состоит в том, чтобы найти минимальное $ C $, при котором выполняется
 \begin{align*}
  P(800 - C \leqslant S_n \leqslant 800 + C) \geqslant \frac{29}{30}.
 \end{align*} 

 По интегральной теореме \ref{theorem:intergram_theorem_muavr_laplas} Муавра-Лапласа эта вероятность приблизительно равна
 \begin{align*}
  P(800 - C \leqslant S_n \leqslant 800 + C) &= P(-C \leqslant S_n - np \leqslant C) = \\
  &= P\left(-\frac{C}{\sqrt{npq}} \leqslant \frac{S_n - np}{\sqrt{npq}} \leqslant \frac{C}{\sqrt{npq}}\right) = \\
  &= P \left( -\frac{C}{20} \leqslant \frac{S_n - np}{\sqrt{npq}} \leqslant \frac{C}{20} \right) \approx \\
  &\approx \frac{1}{\sqrt{2\pi}} \int_{-C / 20}^{C / 20}  e^{-t^{2} / 2} \, dt = \\
  &= 2 (\Phi (C / 20) - \Phi(0))
 .\end{align*} Значит, нам нужно выполнить условие
 \begin{align*}
  \Phi(C/20) - \Phi(0)  \geqslant \frac{29}{60}
 .\end{align*} Табличка говорит, что нужно взять $C/20 \approx 2.13$. Тогда
 \begin{align*}
  C = 20 \cdot 2.13 = 42.6,
 \end{align*} то есть $ 43 $ дополнительных мест будет достаточно.
\end{exmpl}

\begin{exmpl}[случайное блуждание по целым точкам]
 Частица перемещается по целым точкам на прямой. С вероятностью $p$ она идёт в положительную сторону, а с вероятностью $q = 1 - p$ --- в отрицательную. Частица начинает в нуле. Нас интересует, как она будет перемещаться.

 Пусть $a_n$ --- позиция частицы на шаге $n$ ($a_0 = 0$). Тогда
 \begin{align*}
  a_{n+1} = \begin{cases}
   a_n + 1, \text{ с вероятностью } p,  \\
   a_n - 1, \text{ с вероятностью } q.
  \end{cases}
 \end{align*} Здесь удобнее понимать это так: с вероятностью $p$ мы прибавляем $2$, но всегда вычитаем $1$. Тогда
 \begin{align*}
  a_n = 2S_n - n.
 \end{align*} Таким образом, вероятность оказаться в точке $k$ через $n$ шагов равна
 \begin{align*}
  P(a_n = k) = \begin{cases}
   0, \text{ если } k \not \equiv n \pmod 2;  \\
   P(S_n = \frac{n+k}{2}) = \binom {\frac{n+k}{2}} n p^{\frac{n+k}{2}} q^{\frac{n-k}{2}}, \text{ иначе. }
  \end{cases} 
 \end{align*} 
\end{exmpl}

Наконец, завершим параграф ещё одной иллюстрацией вероятностного метода в комбинаторике.

\begin{df}[числа Рамсея]
 \textit{Число Рамсея} $R(n,k)$  --- это такое наименьшее натуральное число $m$, что в любом графе на $m$ вершинах либо есть полный подграф на $n$ вершинах ($n$-клика), либо пустой подграф на $k$ вершинах ($k$-независимое множество).
\end{df}
\begin{thm}[Эрдёша]
 Если $\binom m k \cdot 2^{1 - \frac{k(k-1)}{2}} < 1$, то $R(k,k) > m$. В частности, $R(k,k) > 2^{k / 2}$.
\end{thm}
\begin{proof}[\normalfont\textsc{Доказательство}]
 Рассмотрим случайный граф на $m$  вершинах: для каждой из $\frac{m(m-1)}{2}$ пар вершин возьмём соответствующее ребро с вероятностью $\frac{1}{2}$, независимо от других пар. 

 Для $ k $ вершин $ a_1, \ldots, a_k $ за $ S(a_1, \ldots, a_k) $ обозначим событие <<вершины $ a_1,\ldots,a_k $ подходят>>, то есть <<$ a_1,\ldots,a_k $ образуют либо $ k $-клику, либо $ k $-независимое множество>>. Тогда
 \begin{align*}
  P(S(a_1,\ldots,a_k)) =  \frac{2^{\binom m 2 - \binom k 2}}{2^{\binom m 2}} + \frac{2^{\binom m 2 - \binom k 2}}{2^{\binom m 2}} =  2^{1-\frac{k(k-1)}{2}}.
 \end{align*} За $ S  $ обозначим событие <<какие-то $ k $ вершин подходят>>. С помощью неравенства union bound \eqref{eq:union_bound} оценим вероятность $ S $:
 \begin{align*}
  P(S) &= P \left( \bigcup_{a_1, \ldots, a_k} S(a_1, \ldots, a_k) \right) \leqslant \sum_{a_1, \ldots, a_k}  P(S(a_1,\ldots,a_k)) = \\
  &= \binom m k \cdot 2^{1 - \frac{k(k-1)}{2}} < 1.
 \end{align*} Иными словами, $ P(\overline S) > 0 $. Следовательно, существует граф на $ m $ вершинах, в котором никакие $k$  вершин не подходят.

 Осталось разобраться с <<в частности>>. Подставим целое число $m \leqslant 2^{k / 2}$ и проверим неравенство:
 \begin{align*}
  \binom m k \cdot 2^{1 - \frac{k(k-1)}{2}} &= \frac{m (m-1) \ldots (m - k + 1)}{k!} \cdot 2^{1 - \frac{k(k-1)}{2}} \leqslant \frac{m^{k}}{k!} \cdot 2^{1-\frac{k(k-1)}{2}} \leqslant \\
  &\leqslant \frac{2^{\frac{k^{2}}{2}}}{k!}2^{1 - \frac{k^{2}}{2} + \frac{k}{2}} = \frac{2^{\frac{k}{2} + 1}}{k!}.
 \end{align*}

 Докажем по индукции, что $2^{\frac{k}{2} + 1} < k!$ при $k \geqslant 3$. База $k = 3$ проверяется подстановкой:
 \begin{align*}
  2^{\frac{3}{2} + 1} \approx 5.65 < 6 = 3!.
 \end{align*} При переходе от $k$ к $k + 1$ числитель домножается  на $\sqrt 2$, а знаменатель --- на $(k + 1) > \sqrt 2$.
\end{proof}

\newpage
\part{Общая теория вероятностей.}

В предыдущей части мы изучили элементарную модель теории вероятностей с конечным пространством элементарных исходов. Несмотря на её полезность, нам её будет недостаточно, поскольку мы собираемся изучать непрерывные сущности в теории вероятностей (например, мы хотим научиться выбирать случайное вещественное число из отрезка $ [0,1] $). В связи с этим, мы построим более общую модель теории вероятностей.

\section{Колмогоровская модель теории вероятностей.}

В этой части мы определим вероятностное пространство аксиоматическим подходом, впервые предложенным А.Н. Колмогоровым. Суть его заключается в том, что мы будем определять вероятность не для всех подмножеств пространства элементарных исходов, а для подмножеств, принадлежащих некоторой $ \sigma $-алгебре (то есть семейству множеств, замкнутого относительно счётного объединения/пересечения, дополнения, и содержащего пустое множество).

Таким образом, подход состоит в том, чтобы построить общую теорию вероятностей на почве теории меры, которую мы усердно изучали в третьем семестре математического анализа.

\subsection{Вероятностное пространство.}

Дадим, наконец, первое определение.

\begin{df}[вероятностное пространство]
 \textit{Вероятностным пространством} называется тройка $(\Omega, \mathcal F, P)$ со следующими составляющими.
 \begin{itemize}
  \item $\Omega$ --- множество, называемое \textit{пространством элементарных исходов}. Элементы $ \omega \in \Omega $ называются \textit{элементарными исходами}.
  \item $\F \subset 2^{\Omega}$ --- $\sigma$-алгебра подмножеств $\Omega$, называемая \textit{пространством событий}. Элементы $A \in \F$ называют \textit{случайными событиями} (или просто \textit{событиями}). Напомним, что семейство $ \F \subseteq 2^{\Omega} $ является $ \sigma $-алгеброй, если выполнены следующие три аксиомы.
   \begin{enumerate}
    \item $ \varnothing \in \F $ (пустое множество есть случайное событие).
    \item Если $ A_1, A_2, \ldots \in \F $, то и $\bigcup_{k=1}^{\infty}A_k \in \F$ (счётное объединение случайных событий есть случайное событие).
    \item Если $ A \in \F $, то и $ \overline A \in \F $ (дополнение случайного события есть случайное событие).
   \end{enumerate}
  \item $P \colon\, \F \to [0,1]$ --- \textit{вероятностная мера} на $ \sigma $-алгебре $\F$. То есть, каждому случайному событию $ A \in \F $ поставлено в соответствие неотрицательное число $ P(A) $, называемое \textit{вероятностью} события $ A $, так, что выполнена счётная аддитивность вероятности:
   \begin{align*}
    P \left( \bigsqcup_{k=1}^{\infty}A_k \right) = \sum_{k=1}^{\infty}P(A_k), \qquad A_k \in \mathcal F,
   \end{align*} а также выполнено $P(\Omega) = 1$.
 \end{itemize}
\end{df}

По сути вероятность --- это конечная мера (а вероятностное пространство --- пространство с конечной мерой): условие $ P(\Omega) = 1 $ можно воспринимать лишь как нормировку, сделанную для удобства.

Как и не все множества измеримы в теории меры, так и не всякое подмножество $ \Omega $ имеет вероятность (то есть является \textit{событием}). Тем не менее, обычно измеримых множеств достаточно много.

Покажем явно, что классическая модель теории вероятностей, изученная в предыдущей части, является частным случаем колмогоровской модели, который соответствует вероятностному пространству со считающей мерой.

\begin{exmpl}[дискретное вероятностное пространство]
 Пусть пространство элементарных исходов $\Omega = \left\{ \omega_1, \omega_2, \ldots \right\}$ не более, чем счётно. Пусть $p_1, p_2, \ldots \in [0,1]$ --- вероятности элементарных исходов $\omega_1, \omega_2, \ldots$, причём выполнено $p_1 + p_2 + \ldots  = 1$. Тогда рассмотрим полное пространство событий $\F = 2^{\Omega}$ и для всякого события $A \subset \Omega$ определим его вероятность как сумму конечного или счётного ряда:
 \begin{align*}
  P(A) = \sum_{\omega_i \in A} p_i.
 \end{align*} Полученное вероятностное пространство называется \textit{дискретным}.
\end{exmpl}

Зафиксируем теперь вероятностное пространство $(\Omega, \F, P)$. Перечислим все те же самые простейшие свойства вероятности, которые непосредственно следуют из счётной аддитивности, и которые также были верны в элементарной модели.

\begin{prop}[простейшие свойства вероятности]\
 \begin{enumerate}
  \item $ P(\varnothing) = 0 $, $ P(\Omega) = 1 $, и $ 0 \leqslant P(A) \leqslant 1 $ для всех событий $ A \in \F $.
  \item \textbf{Монотонность}. Если события $ A,B\in\F $ вложены: $ A \subset B $, то
   \begin{align*}
    P(A) \leqslant P(B).
   \end{align*}
  \item \textbf{Вероятность дополнения}.
   \begin{align*}
    P(\overline A) = 1 - P(A)
   \end{align*}
   для всех событий $ A \in \F $.
  \item \textbf{Формула включений-исключений}:
   \begin{align}
    \label{eq:inclusion_exclusion}
    P \left( \bigcup_{i=1}^{m} A_i \right) = \sum_{i=1}^{m}P(A_i) - \sum_{i < j}P(A_i \cap A_j) + \ldots + (-1)^{m+1}P \left( \bigcap_{i=1}^{m}A_i \right)
   \end{align} для любых событий $ A_1, A_2, \ldots, A_m \in \F $.
  \item \textbf{Неравенство union bound}:
   \begin{align*}
    P \left( \bigcup_{k=1}^{\infty}A_k \right) \leqslant \sum_{k=1}^{\infty} P(A_k).
   \end{align*}
 \end{enumerate}
\end{prop}
\begin{proof}[\normalfont\textsc{Доказательство}]
 Все свойства доказываются точно так же, как и для элементарной модели, кроме свойства $ P(\varnothing) = 0 $ (которое легко проверить от противного с помощью счётной аддитивности), и неравенства union bound. Для union bound мы имеем
 \begin{align*}
  P \left( \bigcup_{k=1}^{n}A_k \right) \leqslant \sum_{k=1}^{n}P(A_k)
 \end{align*} для любого конечного $ n $. При стремлении $ n \to \infty $  левая часть стремится к $ P \left( \bigcup_{k=1}^{\infty}A_k \right) $ по непрерывности меры сверху, а правая часть стремится к $ \sum_{k=1}^{\infty} P(A_k)$ (по определению сумму бесконечного ряда). Поэтому, неравенство сохраняется при предельном переходе.
\end{proof}

\subsection{Условная вероятность. Независимость.}

Для зафиксированного вероятностного пространства $ (\Omega,\F,P) $ дадим определения условной вероятности и независимости событий, и снова перечислим их простейшие свойства.

\begin{df}[условная вероятность]
 Пусть $A \in \F$ --- событие, такое, что $P(A) > 0$. Тогда \textit{вероятностью события $B \in \mathcal F$ при условии события $A$} называется число
 \begin{align*}
  P(B \mid A) = \frac{P(A\cap B)}{P(A)}.
 \end{align*}
\end{df}

\begin{prop}[простейшие свойства условной вероятности]\
 \begin{enumerate}
  \item Если $ B \supset A $, то $ P(B\mid A) = 1 $ ($ A,B\in\F $).
  \item $ P(\varnothing \mid A) = 0 $.
  \item Условная вероятность счётно-аддитивна:
   \begin{align*}
    P \left( \bigsqcup_{k=1}^{\infty} B_k \mid A \right) = \sum_{k=1}^{\infty}P(B_k \mid A).
   \end{align*}
  \item $ P(B \mid A) + P(\overline B \mid A) = 1 $.
 \end{enumerate}
\end{prop}

Эти свойства проверяются ровно так же, как и для дискретной модели.

Аналогично верна формула полной вероятности, и более того, она конечно же верна для счётного разбиения.

\begin{prop}[формула полной вероятности]
 Пусть вероятностное пространство разбито на не более, чем счётное число случайных событий:
 \begin{align*}
  \Omega = \bigsqcup_{k=1}^{\infty} A_k, \qquad A_k \in \F,
 \end{align*} причём $ P(A_k) > 0 $ для всех  $ k $. Тогда для любого события $ B \in \F $  верно
 \begin{align*}
  P(B) = \sum_{k=1}^{\infty} P(B \mid A_k) \cdot P(A_k).
 \end{align*}
\end{prop}

Обсудим теперь независимость.

\begin{df}[независимые события]
 Говорят, что два случайных события $A, B \in \F$ \textit{независимы}, если
 \begin{align*}
  P(A \cap B) = P(A) \cdot P(B).
 \end{align*}
\end{df}

\begin{df}[независимость в совокупности]
 Говорят, что случайные события $A_1, \ldots, A_n \in \F$ \textit{независимы в совокупности}, если для любых различных индексов $i_1, \ldots, i_k \in [n]$ верно
 \begin{align*}
  P(A_{i_1}\cap \ldots \cap A_{i_k}) = P(A_{i_1}) \cdot \ldots \cdot P(A_{i_k}).
 \end{align*} 
\end{df}
\begin{conventn*}
 Как и ранее, когда мы будем говорить, что события $A_1, \ldots, A_n$ \textit{независимы}, по умолчанию мы будем иметь в виду независимость в совокупности. \textit{Попарную независимость} мы будем иметь в виду, только если так будет сказано явно.
\end{conventn*}
\begin{remrk}
 \label{remark:independed_complement}
 События $A_1, \ldots, A_n \in \F$ независимы тогда и только тогда, когда для всех наборов событий $\left\{ B_k \right\}_{k=1}^{n}$, где $B_k = A_k$ или $B_k = \overline{A_k}$, верно равенство
 \begin{align}
  \label{equation:remark:independent_complement}
  P(B_1 \cap \ldots \cap B_n) = P(B_1) \cdot\ldots\cdot P(B_n).
 \end{align}
\end{remrk}
\begin{proof}[\normalfont\textsc{Доказательство}]
 Чтобы доказать в одну сторону (из независимости в \eqref{equation:remark:independent_complement}), достаточно показать, что если события $A_1, \ldots, A_{n-1}, A_n$ независимы, то независимы и события $A_1, \ldots, A_{n-1}, \overline{A_n}$. Действительно, если это верно, то мы можем любое подмножество событий заменить на их дополнения без потери независимости, и получить формулу \eqref{equation:remark:independent_complement} для любого набора $\{B_{k}\}_{k=1}^{n} $. Проверим это: пусть $i_1, \ldots, i_{l} \in [n-1]$ --- различные индексы. Тогда по аддитивности верно
 \begin{align*}
  P(A_{i_1} \cap \ldots \cap A_{i_l} \cap A_n) + P(A_{i_1} \cap \ldots \cap A_{i_l} \cap \overline{A_n}) = P(A_{i_1} \cap \ldots \cap A_{i_l}).
 \end{align*} Тогда
 \begin{align*}
  P(A_{i_1} \cap \ldots \cap A_{i_l}\cap \overline{A_n}) &= P(A_{i_1} \cap \ldots \cap A_{i_l}) - P(A_{i_1} \cap \ldots \cap A_{i_l} \cap A_n) = \\
  &= P(A_{i_1})  \ldots  P(A_{i_l}) - P(A_{i_1})  \ldots  P(A_{i_l})  P(A_n) = \\
  &= P(A_{i_1})  \ldots  P(A_{i_l})  (1 - P(A_n)) \\
  &= P(A_{i_1})  \ldots  P(A_{i_l})  P(\overline{A_n}).
 \end{align*} Независимость проверена.

 Наоборот, пусть есть неравенство \eqref{equation:remark:independent_complement} для любого набора $B_k$. Возьмём любой набор различных индексов $I = \left\{i_1, \ldots, i_l \right\} \subset [n]$. Пусть $[n] \setminus I = \left\{ j_1, \ldots, j_{n-l} \right\}$ --- оставшиеся индексы. Тогда по аддитивности
 \begin{align*}
  P(A_{i_1} \cap \ldots \cap A_{i_l}) = \sum_{\{B_{j_t}\}_{t=1}^{n-l} } P(A_{i_1} \cap \ldots \cap A_{i_l} \cap B_{j_1} \cap \ldots \cap B_{j_{n-l}}),
 \end{align*} где сумма берётся по всем наборам $ \{B_{j_t}\}_{t=1}^{n-l} $ таким, что $B_{j_t} = A_{j_t}$ или $B_{j_t} = \overline{A_{j_t}}$. По равенству \eqref{equation:remark:independent_complement}:
 \begin{align*}
  P(A_{i_1} \cap \ldots \cap A_{i_l}) &= \sum_{\{B_{j_t}\}_{t=1}^{n-l} } P(A_{i_1}) \ldots P(A_{i_l}) \cdot P(B_{j_1}) \ldots P(B_{j_t}) = \\
  &= P(A_{i_1}) \ldots P(A_{i_l}) \cdot \sum_{\{B_{j_t}\}_{t=1}^{n-l} } P(B_{j_1}) \ldots P(B_{j_t}) = \\
  &= P(A_{i_1}) \ldots P(A_{i_l}) \cdot \prod_{t=1}^{n-l} (P(A_{j_t}) + P(\overline{A_{j_t}})) = \\
  &= P(A_{i_1}) \ldots P(A_{i_l}).
 \end{align*} 
\end{proof}

Таким образом, среди независимых событий можно свободно переходить к их дополнениям без потери независимости.

\begin{df}[независимость бесконечного числа событий]
 Говорят, что счётное число случайных событий $A_1, A_2, \ldots \in \F$ \textit{независимы}, если любое их конечное подмножество независимо. Эквивалентно, для любого конечного набора различных индексов $i_1, \ldots, i_n$ верно
 \begin{align*}
  P(A_{i_1} \cap \ldots \cap A_{i_n}) = P(A_{i_1}) \cdot \ldots \cdot P(A_{i_n}).
 \end{align*} 
\end{df}
\begin{remrk}
 \label{remark:independent_infinite_product}
 Если события $A_1, A_2, \ldots \in \F$  независимы, то
 \begin{align*}
  P \left( \bigcap_{k=1}^{\infty} A_k \right) = \prod_{k=1}^{\infty} P(A_k).
 \end{align*} 
\end{remrk}
\begin{proof}
 Для любого конечного $n$ имеем
 \begin{align*}
  P \left( \bigcap_{k=1}^{n} A_k \right) = \prod_{k=1}^{n} P(A_k)
 .\end{align*} В пределе при $n \to \infty$ правая часть стремится к бесконечному произведению. Так как множества $ \bigcap_{k=1}^{n}A_k  $ убывают при $ n \to \infty $, то по непрерывности меры снизу левая часть стремится к  $ P( \bigcap_{k=1}^{\infty} A_k)  $.
\end{proof}
\begin{lm}[%
 Бореля-Кантелли]
 \label{lemma:borel_cantelli}
 Пусть $A_1, A_2, \ldots \in \F$  --- случайные события. Обозначим за $ B \in \F$ событие <<среди событий $ A_k $ случилось бесконечно много событий>>:
 \begin{align*}
  B = \bigcap_{n=1}^{\infty} \bigcup_{k \geqslant n} A_k.
 \end{align*} Также обозначим неотрицательный ряд вероятностей
 \begin{align*}
  S = \sum_{k=1}^{\infty} P(A_k).
 \end{align*}  Тогда:
 \begin{enumerate}
  \item \label{enum1:lemma:borel_cantelli} Если ряд $ S $ сходится, то $P(B) = 0$.
  \item \label{enum2:lemma:borel_cantelli} Если события $A_k$  независимы и ряд $ S $ расходится к $ +\infty $, то $P(B) = 1$.
 \end{enumerate} 
\end{lm}
\begin{proof}[\normalfont\textsc{Доказательство}]\
 \begin{enumerate}
  \item Этот пункт был доказан на матане, но доказательство простое:
   \begin{align*}
    P(B) \leqslant P \left( \bigcup_{k \geqslant n} A_k \right) \leqslant \sum_{k \geqslant n} P(A_k) \to 0,
   \end{align*} где правая часть стремится к нулю как хвост сходящегося ряда $ S $.

  \item Докажем второй пункт. Обозначим $B_k = \overline {A_k}$. События $B_1, B_2, \ldots$ независимы по замечанию \ref{remark:independed_complement}. По замечанию \ref{remark:independent_infinite_product} для любого $ n \geqslant 1$:
   \begin{align*}
    P \left( \bigcap_{k \geqslant n} B_k \right) = \prod_{k \geqslant n} P(B_k) = \prod_{k \geqslant n} (1 - P(A_k)).
   \end{align*} Пользуясь неравенством $ 1 + x \leqslant e^{x} $, получаем 
   \begin{align*}
    P \left( \bigcap_{k \geqslant n} B_k \right) \leqslant \prod_{k \geqslant n} e^{-P(A_k)} = \exp \left(-\sum_{k \geqslant n} P(A_k)\right) = 0,
   \end{align*} так как $ \sum_{k \geqslant n} P(A_k) = +\infty $ для любого $ n $ (хвост расходящегося неотрицательного ряда). Следовательно,
   \begin{align*}
    P \left( \overline { \bigcap_{k \geqslant n} B_k } \right) = 1 \implies P \left( \bigcup_{k \geqslant n} A_k \right) = 1
   \end{align*} для всякого $ n \geqslant 1 $. Кроме того, множества $\bigcup_{k \geqslant n} A_k$ убывают при $ n \to \infty $, поэтому по непрерывности меры снизу имеем
   \begin{align*}
    P(B) = P \left( \bigcap_{n=1}^{\infty} \bigcup_{k \geqslant n} A_k \right) = \lim_{n \to \infty} P \left( \bigcup_{k \geqslant n}^{\infty} A_k \right) = 1.
   \end{align*}
 \end{enumerate}
\end{proof}
\begin{crly*}[закон нулей и единиц]
 Пусть события $A_1, A_2, \ldots \in \F$ независимы. Тогда вероятность того, что случилось бесконечное число из них равна либо нулю, либо единице. 
\end{crly*}

\newpage
\section{Случайные величины.}

\subsection{Случайная величина.}

На самом деле, мы уже сталкивались со случайными величинами в первой части, однако пока мы не вводили соответствующее определение. Например, число $ S_n $ успехов в схеме Бернулли является случайной величиной. Грубо говоря, случайная величина --- это число, которое зависит от элементарного исхода, то есть это функция вида $ \Omega \to \R $.

Однако, как и не любое подмножество $ \Omega $ является случайным событием, так и не любая функция из $ \Omega $ будет случайной величиной. Дадим формальное определение.

\begin{df}[%
 случайная величина]
 Пусть $(\Omega, \F, P)$ --- вероятностное пространство. \textit{Случайной величиной} называется измеримая функция $\xi \colon\, \Omega \to \R$.
\end{df}

Напомним, что функция $ \xi \colon\, \Omega \to \R $ называется \textit{измеримой} (относительно $ \sigma $-алгебры $ \F $), если $ \xi^{-1}((a, +\infty)) \in \mathcal F $ для всякого $ a \in \R \cup \{\pm \infty\} $. Как мы увидели на теории меры, почти все  встречающиеся на практике функции так или иначе измеримы, то есть это условие довольно-таки слабое. Кроме того, из измеримости функции $ \xi $ следует $ \xi^{-1}(B) \in \F $ для всех борелевских множеств $ B \in \B_1 $. Это очень удобно, ведь все множества вида $ \left\{ \xi \in B \right\} $ являются случайными событиями, а значит, имеют вероятность.

Для общего развития отметим, что можно не ограничиваться отображениями из пространства элементарных исходов в $ \R $, а определить так называемый \textit{случайный элемент}.

\begin{df*}[случайный элемент]
 Пусть $ (\Omega,\F,P) $ --- вероятностное пространство, а $ (E, \mathcal E) $ --- измеримое пространство (множество $ E $ с заданной на нём $ \sigma $-алгеброй $ \mathcal E $). \textit{Случайным элементом} из $ E $ называется $ (\F,\mathcal E) $-измеримая функция $ \xi \colon\,\Omega\to E $, где $ (\F,\mathcal E) $-измеримость означает $\xi^{-1}(B) \in \F$ для всех измеримых множеств $ B \in \mathcal E $.
\end{df*}

В частности, случайная величина --- это случайный элемент, где $ (E,\mathcal E) = (\R, \B_1) $.

Мы не будем пользоваться определением случайного элемента. Максимум из этого: в следующем параграфе будет введено понятие \textit{случайного вектора}, где $ (E, \mathcal E) = (\R^{n}, \B_n) $. Но в этом случае $ (\F,\B_n) $-измеримость равносильна измеримости координатных функций, так что случайный вектор мы будем понимать лишь как кортеж из случайных величин.

\subsection{Распределение. Функция распределения.}

\begin{df}[%
 распределение случайной величины]
 Пусть $ (\Omega,\F,P) $ --- вероятностное пространство.
 \textit{Распределением случайной величины} $\xi \colon\,\Omega\to\R$ называется мера $ P_{\xi} \colon\, \mathcal B_1 \to [0, 1] $ на борелевских подмножествах $\R$, заданная по формуле
 \begin{align*}
  P_{\xi}(B) = P(\xi \in B) = P(\xi^{-1}(B)).
 \end{align*} 
\end{df}

\begin{remrk}
 Легко видеть, что распределение всякой случайной величины задано корректно (ведь $ \xi^{-1}(B) \in \F $ при $ B \in \B_1 $) и является мерой: ведь под действием прообраза $ \xi^{-1} $ всякое счётное дизъюнктное объединение $ B_1 \sqcup B_2 \sqcup \ldots $ борелевских множеств $ B_1, B_2, \ldots \in \B_1 $ переходит в счётное дизъюнктное объединение $ \xi^{-1}(B_1) \sqcup \xi^{-1}(B_2) \sqcup \ldots $ измеримых множеств. Более того, распределение $ P_\xi $ является вероятностной мерой ($ P_\xi(\R) = 1 $), так как $ \xi^{-1}(\R) = \Omega $.
\end{remrk}

\begin{remrk}
 Можно считать, что распределение случайной величины $ \xi $ осуществляет переход из вероятностного пространства $ (\Omega,\F,P) $ в вероятностное пространство $ (\R,\B_1,P_\xi) $. В новом вероятностном пространстве вероятность борелевского множества $ B \in \B_1 $ равна вероятности того, что $ \xi $ попадёт в это множество $ B $.
\end{remrk}

\begin{df}
 Говорят, что случайные величины $\xi$, $\eta$ \textit{одинаково распределены}, если их распределения совпадают как меры: $P_{\xi} = P_{\eta}$.

 При этом определение допускает, что величины $ \xi $ и $ \eta $ могут быть заданы на разных вероятностных пространствах.
\end{df}
\begin{remrk}
 \label{remark:_distribution_eq}
 Из единственности стандартного продолжения меры (теорема Каратеодори), равенство распределений $P_{\xi} = P_{\eta}$  достаточно проверять на ячейках:
 \begin{align*}
  P_{\xi} \left(a, b\right] = P_{\eta} \left(a, b\right]  
  ,\end{align*} что эквивалентно \begin{align*}
  P(\xi \leqslant b) - P(\xi \leqslant a) =  P(\eta \leqslant b) - P(\eta \leqslant a).
 \end{align*}

 Более того, достаточно, чтобы для всех $a \in \R$ выполнялось
 \begin{align*}
  P(\xi \leqslant a) = P(\eta \leqslant a).
 \end{align*} Это замечание подталкивает к определению \textit{функции распределения}.
\end{remrk}
\begin{df}[%
 функция распределения]
 Пусть $ (\Omega,\F,P) $ --- вероятностное пространство. \textit{Функцией распределения} случайной величины $\xi \colon\,\Omega\to\R$ называется функция $F_{\xi} \colon\, \R \to \R$, определённая по формуле
 \begin{align*}
  F_{\xi}(x) = P(\xi \leqslant x).
 \end{align*} 
\end{df}
\begin{remrk}
 Как следует из замечания \ref{remark:_distribution_eq}, если случайные величины $ \xi $ и $ \eta $ имеют одинаковые функции распределения, то они одинаково распределены.
\end{remrk}
\begin{prop}[cвойства функции распределения]\
 \begin{enumerate}
  \item $0 \leqslant F_{\xi}(x) \leqslant 1$ для всех $ x \in \R $.
  \item \label{enum2:prop:distribution_function} $F_{\xi}$  нестрого возрастает.
  \item \label{enum3:prop:distribution_function} $\lim\limits_{x \to +\infty} F_{\xi}(x) = 1$  и $\lim\limits_{x \to -\infty} F_{\xi}(x) = 0$.
   \begin{proof}[\normalfont\textsc{Доказательство}]
    Непрерывность меры сверху (стремление к $\Omega$) и снизу (стремление к $\varnothing$).
   \end{proof}
  \item \label{enum4:prop:distribution_function} $F_{\xi}$  непрерывна справа.
   \begin{proof}[\normalfont\textsc{Доказательство}]
    Возьмём любую убывающую последовательность точек $y_n \to x$, $y_n > x$. Тогда
    \begin{align*}
     F_{\xi}(y_n) = P(\xi \leqslant y_n) = P(A_n)
    .\end{align*} Множества $A_n$ убывают. По непрерывности меры снизу получаем
    \begin{align*}
     F_{\xi}(y_n) \to P \left( \bigcap_{n=1}^{\infty} A_n \right) = P(\xi \leqslant x).
    \end{align*} 
   \end{proof}
  \item $F_{\xi + c}(x) = F_{\xi}(x - c)$.
  \item Если $c > 0$, то $F_{c\xi}(x) = F_{\xi}(x / c)$.
  \item $P(\xi < x) = \lim\limits_{y \to x-} F_{\xi}(y)$.
 \end{enumerate}
\end{prop}
\begin{remrk}
 Любая функция, удовлетворяющая свойствам \ref{enum2:prop:distribution_function}, \ref{enum3:prop:distribution_function}, \ref{enum4:prop:distribution_function} (нестрогому возрастанию, правильным пределам при $ x \to \pm \infty $ и непрерывности справа) есть функция распределения некоторой случайной величины.
\end{remrk}
\begin{proof}[\normalfont\textsc{Доказательство}]
 Пусть $F$ --- такая функция. Рассмотрим функцию множества
 \begin{align*}
  \nu \left(a, b\right] = F(b) - F(a),
 \end{align*} заданную на полукольце ячеек $ \mathcal P_1 $. Функция $ \nu $ является неотрицательной (так как $ F $ нестрого возрастает по свойству \ref{enum2:prop:distribution_function}), а также счётно-аддитивной (так как она непрерывна справа по свойству \ref{enum3:prop:distribution_function}, но это требует доказательства). По теореме Каратеодори существует мера $ \nu $ --- её стандартное продолжение на некоторую $ \sigma $-алгебру $ \mathfrak A $ подмножеств $ \R $. При этом мера $ \nu $ --- вероятностная, так как по свойству \ref{enum4:prop:distribution_function} и непрерывности меры сверху
 \begin{align*}
  \nu(\R) = \lim_{x \to +\infty} \nu \left(-x, x\right] = \lim_{x \to +\infty} F(x) - \lim_{x \to -\infty} F(x) = 1. 
 \end{align*} Таким образом, мы получили вероятностное пространство $ (\R,\mathfrak A, \nu) $. Случайная величина $ \xi \colon\, \R \to \R $, $ \xi(\omega) = \omega $ как раз даёт нужное распределение $ F $.
\end{proof}

\begin{df}[%
 дискретное распределение]
 Говорят, что случайная величина обладает \textit{дискретным распределением}, если её область значений не более, чем счётная. В таком случае случайная величина называется \textit{дискретной}.
\end{df}
\begin{remrk}
 Пусть $\xi \colon\, \Omega \to \left\{ y_1, y_2, \ldots \right\}$ --- дискретная случайная величина. Для каждого $ k \geqslant 1 $ обозначим $ p_k = P(\xi = y_k) $. Тогда для любого борелевского множества $ A \subset \R $
 \begin{align*}
  P_{\xi}(A) = \sum_{y_k \in A}  p_k.
 \end{align*} Иными словами, распределение $ P_\xi $ является считающей мерой в точках  $ y_1, y_2, \ldots $  с коэффициентами $ p_1, p_2, \ldots $:
 \begin{align*}
  P_\xi = \sum_{k=1}^{\infty} p_k \delta_{ y_k },
 \end{align*} где $ \delta_{y } $ --- дельта-мера Дирака (мера, считающая точку $ y \in \R $).

 Действительно, это следует из счётно-аддитивности функции распределения $ P_{\xi} $. Таким образом, дискретная случайная величина (при фиксированном множестве значений $ \left\{ y_1, y_2, \ldots \right\} $) однозначно определяется счётным набором вероятностей $ p_1, p_2, \ldots \in [0,1] $, $ p_1 + p_2 + \ldots = 1 $, $ p_k = P(\xi = y_k) $.

 В частности, функцию распределения дискретной величины $ \xi $ можно выразить так:
 \begin{align*}
  F_{\xi}(x) = \sum_{y_k \leqslant x} p_k.
 \end{align*} 
\end{remrk}

\subsection{Непрерывные распределения. Плотность.}

\begin{df}[непрерывное распределение]
 Говорят, что случайная величина $\xi$ \textit{обладает непрерывным распределением}, если $P(\xi = x) = 0$ для всех $x \in \R$.
\end{df}

\begin{remrk}
 Случайная величина $ \xi $ обладает непрерывным распределением тогда и только тогда, когда её функция распределения $ F_{\xi} $ является непрерывной.
\end{remrk}
\begin{proof}[\normalfont\textsc{Доказательство}]
 Пусть $ \xi $ обладает непрерывным распределением. Непрерывность справа есть и так, поэтому достаточно проверить непрерывность слева в произвольной точке $ x \in \R $:
 \begin{align}
  \label{equation:remark:left_continous_of_distribution}
  \lim_{y \to x-} F_{\xi}(y) &= P(\xi < x) = P(\xi \leqslant x) - P(\xi = x) = P(\xi \leqslant x) = F_{\xi}(x).
 \end{align} Наоборот, если функция распределения непрерывна, то верна цепочка \eqref{equation:remark:left_continous_of_distribution} для любой точки $ x \in \R $, из чего следует $ P(\xi = x) = 0 $.
\end{proof}

Зачастую непрерывности распределения случайной величины недостаточно. Гораздо удобнее работать со следующим более сильным условием.

\begin{df}[абсолютная непрерывность, плотность]
 Говорят, что  случайная величина $\xi$ \textit{абсолютно непрерывна} (\textit{обладает абсолютно непрерывным распределением}), если существует неотрицательная измеримая функция $p_{\xi} \colon\, \R \to [0, +\infty)$, называемая \textit{плотностью распределения} случайной величины $ \xi $,  такая, что для любой точки $ x \in \R $ выполнено
 \begin{align}
  \label{equation:density_def}
  F_{\xi}(x) = \int_{-\infty}^{x} p_{\xi}(t)\,dt
 .\end{align}
\end{df}
\begin{prop}[свойства плотности]
 Пусть случайная величина $ \xi $ обладает абсолютно непрерывным распределением, а $ p_{\xi} $ --- её плотность распределения. Тогда
 \begin{enumerate}
  \item Для любого борелевского множества $ A \subset \R $ выполнено
   \begin{align}
    \label{equation:value_of_absolute_continous_distribution}
    P(\xi \in A) = \int_{A} p_{\xi} (t) \, dt.
   \end{align} 
  \item Выполнено нормировочное условие
   \begin{align*}
    \int_{\R} p_{\xi}(t)\,dt = 1.
   \end{align*}
  \item Функция распределения $ F_\xi $ дифференцируема в почти всех точках $ x \in \R $, и в этих точках выполнено равенство
   \begin{align*}
    F'_{\xi}(x) = p_{\xi}(x).
   \end{align*}
 \end{enumerate}
\end{prop}
\begin{proof}[\normalfont\textsc{Доказательство}]\
 \begin{enumerate}
  \item Равенство \eqref{equation:value_of_absolute_continous_distribution} можно рассматривать как равенство двух мер: $ P_\xi(A) = \int_{A} p_\xi \, d\lambda_1  $. По теореме Каратеодори равенство \eqref{equation:value_of_absolute_continous_distribution} достаточно проверять на ячейках. А равенство на ячейках немедленно следует из \eqref{equation:density_def}.
  \item Достаточно подставить множество $ A = \R $ в равенство \eqref{equation:value_of_absolute_continous_distribution}.
  \item Здесь применяется теорема о точках Лебега из курса теории меры. Так как функция $ p_\xi \in L^{1}(\R, \lambda_1)$  суммируема, то почти все точки $ x \in \R $ являются точками Лебега функции  $ p_\xi $, то бишь выполнено равенство
   \begin{align*}
    \lim_{r \to 0} \frac{1}{2r} \int_{x-r}^{x+r} \left| p_\xi(y) - p_\xi(x) \right|dy = 0.
   \end{align*} Так как подынтегральное выражение неотрицательно, то выражение под пределом можно разбить на два неотрицательных слагаемых:
   \begin{align*}
    \frac{1}{2r}\int_{x}^{x+r} \left| p_\xi(y)-p_\xi(x) \right|dy + \frac{1}{2r} \int_{x-r}^{x} \left| p_\xi(y)-p_\xi(x) \right|dy,
   \end{align*} каждое из которых обязано стремится к нулю. В частности, получаем
   \begin{align*}
    \lim_{r \to 0} \frac{1}{r} \int_{x}^{x+r} ( p_\xi(y) - p_\xi(x) )\,dy = 0 \implies \lim_{r \to 0} \frac{1}{r}\int_{x}^{x+r} p_\xi(y)\,dy = p_\xi(x).
   \end{align*} Поэтому,
   \begin{align*}
    \lim_{r \to 0} \frac{F_\xi(x + r) - F_\xi(x)}{r} &= \lim_{r \to 0} \frac{1}{r} \int_{x}^{x+r} p_\xi(y)\,dy = p_\xi(x).
   \end{align*} То есть $ F_\xi'(x) = p_\xi(x) $ для почти всех $ x\in\R $.
 \end{enumerate}
\end{proof}

\begin{prop}[арифметические свойства плотности]
 Пусть случайная величина $ \xi $ абсолютно непрерывна. Тогда
 \begin{enumerate}
  \item Случайная величина $ \xi + c $, где $ c \in \R $ --- константа, абсолютно непрерывна, и выполнено
   \begin{align*}
    p_{\xi + c}(t) = p_\xi(t - c).
   \end{align*}
  \item Случайная величина $ c\xi $, где $ c > 0 $, абсолютно непрерывна, и выполнено
   \begin{align*}
    p_{c\xi}(t) = \frac{p_\xi(t / c)}{c}.
   \end{align*}
  \item Случайная величина $ -\xi $ абсолютно непрерывна, и выполнено
   \begin{align*}
    p_{-\xi}(t) = p_\xi(-t).
   \end{align*}
 \end{enumerate}
\end{prop}
\begin{proof}[\normalfont\textsc{Доказательство}]\
 \begin{enumerate}
  \item В самом деле,
   \begin{align*}
    F_{\xi+c}(x) = F_\xi(x - c) = \int_{-\infty}^{x - c} p_\xi(t)\,dt = \begin{bmatrix}
     t = u - c & dt = du
    \end{bmatrix} = \int_{-\infty}^{x} p_\xi(u - c)\,du,
   \end{align*} поэтому функция $ t \mapsto p_\xi(t - c) $  подходит под определение плотности случайной величины $ \xi + c $.
  \item Аналогично,
   \begin{align*}
    F_{c\xi}(x) = F_{\xi}(x / c) = \int_{-\infty}^{x / c} p_\xi(t)\,dt = \begin{bmatrix}
     t = u / c & dt = du / c
    \end{bmatrix} = \int_{-\infty}^{x} \frac{p_\xi(u / c)}{c}\,du,
   \end{align*} поэтому функция $ t \mapsto \frac{p_\xi(t / c)}{c} $  --- плотность $ c\xi $.
  \item Наконец,
   \begin{align*}
    F_{-\xi}(x) &= P(\xi \geqslant -x) = \int_{-x}^{+\infty} p_\xi(t)\,dt = \begin{bmatrix}
     t = -u & dt = -du
    \end{bmatrix} = \\
    &= \int_{x}^{-\infty} p_\xi(-u)\,(-du) = \int_{-\infty}^{x} p_\xi(-u)\,du,
   \end{align*} поэтому функция $ t \mapsto p_\xi(-t) $ --- плотность $ -\xi $.
 \end{enumerate}
\end{proof}

\end{document}
