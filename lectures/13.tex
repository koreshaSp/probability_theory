% 2023.05.23 lecture 13
\documentclass[../main.tex]{subfiles}
\begin{document}

\begin{exmpl}[управление запасами]
 Есть склад, на складе может быть максимум $ S $ единиц товара. Пусть $ \eta_i $ --- это спрос на товар в момент времени $ i $. Будем считать, что $ \eta_i $ --- независимые случайные величины. Если единиц товара в какой-то момент становится меньше некоторого порога в $ s $ единиц, то склад заполняется до максимума. При этом мы считаем $ \eta_n \leqslant s $ всегда.

 Обозначим за $ \xi_n $ количество единиц товара на складе в момент времени $ n $. Оно определяется так:
 \begin{align*}
  \xi_n = \begin{cases}
   \xi_{n-1} - \eta_n, \text{ если }  \xi_{n-1} \geqslant s, \\
   S - \eta_n, \text{ если } \xi_{n-1} < s.
  \end{cases}
 \end{align*}

 Получили цепь Маркова.
\end{exmpl}

\newpage
\section{Случайные блуждания.}

В последнем параграфе мы подробнее изучим частный случай цепи Маркова: случайное блуждание.

\subsection{Случайное блуждание по \texorpdfstring{$\Z$}{целой прямой}.}

Сначала исследуем классический вариант случайного блуждания по $ \Z $, приведённый в примере \ref{exmpl:random_walk_z}: когда мы можем идти только направо или налево.

\begin{thm}
 \label{theorem:random_walk_on_Z_d_back}
 Случайное блуждание по $ \Z $ возвратно (то есть вероятность вернуться в изначальную точку $ 0 $ равна единице), если и только если $ p = 1 / 2 $.
\end{thm}
\begin{proof}[\normalfont\textsc{Доказательство}]
 По критерию возвратности (теорема \ref{theorem:back_criteria}) состояние $ 0 $ возвратно, если и только если ряд расходится
 \begin{align}
  \label{eq:theorem:random_walk_z_back:series}
  \sum_{n=1}^{\infty}p_{00}(n) = +\infty.
 \end{align} Выразим общий член ряда:
 \begin{align*}
  &p_{00}(2n+1)= 0, \\
  &p_{00}(2n) = \binom{2n} n \cdot p^{n}(1-p)^{n} \sim \frac{(4p(1-p))^{n}}{\sqrt{\pi n}}.
 \end{align*} 

 Если $ p = 1 / 2 $, то
 \begin{align*}
  p_{00}(2n) \sim \frac{1}{\sqrt{\pi n}},
 \end{align*} и ряд \eqref{eq:theorem:random_walk_z_back:series} расходится. Если же $ p \neq 1 / 2 $, то
 \begin{align*}
  p_{00}(2n) = \OO \left( (4p(1-p))^{n} \right),
 \end{align*} и ряд сходится, ведь $ 4p(1-p) < 1 $.
\end{proof}

Теперь обобщим процесс случайного блуждания по $ \Z $: разрешим переходить не только направо или налево, а произвольным образом.

\begin{df}[произвольное изотропное блуждание]
 Пусть случайные величины $ \eta_1,\eta_2,\ldots $ независимы, одинаково распределены, и их распределение принимает только целые значения. Тогда цепь Маркова с фазовым пространством $ Y = \Z $ и последовательностью случайных величин
 \begin{align*}
  \xi_n = \eta_1 + \eta_2 + \ldots + \eta_n, \quad n \geqslant 0
 \end{align*} называется \textit{произвольным изотропным случайным блужданием по $ \Z $}.
\end{df}

\begin{df}[симметричное блуждание]
 Произвольное изотропное случайное блуждание по $ \Z $ называется \textit{симметричным}, если его распределение переходов симметрично:
 \begin{align*}
  P(\eta_1 = a) = P(\eta_1 = -a)
 \end{align*} для всех $ a \in \Z $.
\end{df}

\begin{thm}
 \label{theorem:symmetrical_random_walk_on_Z}
 Симметричное произвольное изотропное случайное блуждание по $ \Z $, распределение переходов которого имеет математическое ожидание, возвратно.
\end{thm}
\begin{remrk*}
 Если математическое ожидание распределения переходов симметричного блуждания есть, то оно обязательно равно нулю.
\end{remrk*}
\begin{proof}[\normalfont\textsc{Доказательство теоремы \ref{theorem:symmetrical_random_walk_on_Z}}]\
 По критерию возвратности (теорема \ref{theorem:back_criteria}) достаточно доказать, что ряд расходится:
 \begin{align}
  \label{eq:symmetrical_random_walk_on_Z:main_series_to_prove}
  \sum_{n=0}^{\infty}p_{00}(n) = +\infty.
 \end{align}

 Пусть $ G(z) $ --- производящая функция распределения переходов. Обратим внимание на то, что здесь $ G(z) $ не степенной ряд, а ряд Лорана:
 \begin{align*}
  G(z) = \sum_{k \in \Z} P(\eta_1 = k) \cdot z^{k}.
 \end{align*} Пока-что мы рассматриваем этот ряд лишь как формальную запись.

 Заметим, что для всякого $ n \geqslant 0 $ верно
 \begin{align*}
  G(z)^{n} = \sum_{k \in \Z} P(\xi_n = k) \cdot z^{k}.
 \end{align*} Это легко проверить по индукции. База $ n=0 $ очевидна: $ G(z)^{0} = 1 $. Переход $ n \to n+1 $:
 \begin{align*}
  P(\xi_{n+1} = k) &= \sum_{l \in \Z} P(\xi_{n+1} = k \mid \xi_n = l) \cdot P(\xi_n = l) = \\
  &= \sum_{l \in \Z}P(\eta_1 = k - l) \cdot P(\xi_n = l) = \\
  &= G(z) \cdot G(z)^{n} = G(z)^{n+1}.
 \end{align*}

 Докажем, что для любого $ n \geqslant 0 $  выполнено равенство
 \begin{align}
  \label{eq:symmetrical_random_walk_on_Z:2_pi_i_integral}
   P(\xi_n = 0) = \frac{1}{2\pi i} \int\limits_{\left| z \right|=1}   \frac{G(z)^{n}}{z}\,dz.
 \end{align}

 Заметим, что ряд Лорана $G(z)^{n}$ при любом $ n \geqslant 0 $ сходится на комплексной окружности $ \left| z \right|=1 $, причём сходимость равномерная по $ z $ по признаку Вейерштрасса:
 \begin{align*}
  \left| \sum_{k\in\Z}P(\xi_n=k) \cdot z^{k} \right| \leqslant \sum_{k \in \Z}P(\xi_n=k) \cdot \left| z \right|^{k} = \sum_{k \in\Z}P(\xi_n = k) = 1.
 \end{align*} Поэтому, функция $ G(z)^{n} $, как минимум, определена и непрерывна на единичной окружности.

 Раскроем правую часть равенства \eqref{eq:symmetrical_random_walk_on_Z:2_pi_i_integral}:
 \begin{align*}
  \frac{1}{2\pi i} \int\limits_{\left| z \right|=1}   \frac{G(z)^{n}}{z}\,dz &= \begin{bmatrix}
   z = e^{it}, & dz = ie^{it}\,dt
  \end{bmatrix} = \frac{1}{2\pi i} \int_{-\pi}^{\pi} \frac{G(e^{it})^{n}}{e^{it}} \cdot ie^{it}\,dt = \\
  &= \frac{1}{2\pi} \int_{-\pi}^{\pi} G(e^{it})^{n}\,dt = \frac{1}{2\pi} \int_{-\pi}^{\pi} \left[ \sum_{k \in \Z}P(\xi_n=k) \cdot e^{itk} \right]dt.
 \end{align*} Так как двойной интеграл сходится абсолютно:
 \begin{align*}
  \int_{-\pi}^{\pi} \left[ \sum_{k \in \Z} \left| P(\xi_n = k) \cdot e^{itk} \right| \right]dt = \int_{-\pi}^{\pi} 1\,dt = 2\pi < +\infty,
 \end{align*} то по теореме Фубини можно переставить интеграл и сумму местами:
 \begin{align*}
  \frac{1}{2\pi i} \int\limits_{\left| z \right|=1}  \frac{G(z)^{n}}{z}\,dz &= \frac{1}{2\pi} \sum_{k \in \Z} P(\xi_n = k) \cdot \int_{-\pi}^{\pi} e^{itk}\,dt = \\
  &= \frac{1}{2\pi} \sum_{k \in \Z} P(\xi_n = k) \cdot \begin{cases}
   2\pi, \text{ если } k = 0  \\
   0, \text{ иначе }
  \end{cases} = \\
  &= P(\xi_n = 0).
 \end{align*} Равенство \eqref{eq:symmetrical_random_walk_on_Z:2_pi_i_integral} доказано.

 Далее, возьмём любое число $ 0 < \delta < 1 $. Домножим на $ \delta^{n} $ каждый член ряда \eqref{eq:symmetrical_random_walk_on_Z:main_series_to_prove}, и оценим асимптотику того, что получилось:
 \begin{align*}
  \sum_{n=0}^{\infty} \delta^{n}P(\xi_n = 0) &= \sum_{n=0}^{\infty} \delta^{n} \cdot \frac{1}{2\pi i} \left[\int_{\left| z \right|=1} \frac{G(z)^{n}}{z}\,dz \right] = \sum_{n=0}^{\infty}\frac{\delta^{n}}{2\pi} \left[ \int_{-\pi}^{\pi} G(e^{it})^{n}\,dt. \right]
 \end{align*} Так как двойной интеграл сходится абсолютно:
 \begin{align*}
  \sum_{n=0}^{\infty} \frac{\delta^{n}}{2\pi} \left[ \int_{-\pi}^{\pi} \left| G(e^{it})^{n} \right|\,dt \right] \leqslant \sum_{n=0}^{\infty} \frac{\delta^{n}}{2\pi} \left[ \int_{-\pi}^{\pi} 1\,dt \right] = \sum_{n=0}^{\infty}\delta^{n} < +\infty,
 \end{align*} то по теореме Фубини
 \begin{align*}
  \sum_{n=0}^{\infty}\delta^{n}P(\xi_n=0) &= \frac{1}{2\pi} \int_{-\pi}^{\pi} \left[\sum_{n=0}^{\infty} \delta^{n}G(e^{it})^{n} \right]dt.
 \end{align*} Далее, так как $ \left| \delta G(e^{it}) \right| < 1 $ , то сумму геометрической прогрессии можно свернуть:
 \begin{align*}
  \sum_{n=0}^{\infty}\delta^{n}P(\xi_n=0) &= \frac{1}{2\pi} \int_{-\pi}^{\pi} \frac{dt}{1 - \delta G(e^{it})}.
 \end{align*} Для удобство воспользуемся равенством $ G(e^{-it}) = G^{e^{it}} $ , которое следует из симметричности случайного блуждания:
 \begin{align*}
  \sum_{n=0}^{\infty}\delta^{n}P(\xi_n=0) &= \frac{1}{\pi} \int_{0}^{\pi} \frac{dt}{1 - \delta G(e^{it})}.
 \end{align*} Также заметим, что левая часть вещественная, поэтому в правой части можно интегрировать лишь вещественную часть:
 \begin{align*}
  \sum_{n=0}^{\infty}\delta^{n}P(\xi_n=0) &= \frac{1}{\pi} \int_{0}^{\pi} \frac{dt}{1 - \delta \Real G(e^{it})}.
 \end{align*} При этом заметим, что так как $ \left| \delta \Real G(e^{it}) \right| < 1 $, то справа интегрируется неотрицательная функция.

 Далее, так как распределение переходов по условию имеет нулевое математическое ожидание, то функция $ G(z) $ дифференцируема в точке $ z = 1 $, и $ G'(1) = 0 $. Тогда по формуле Тейлора получаем
 \begin{align*}
  G(e^{it}) = 1 + o(t)
 \end{align*} при $ t \to 0 $. Подставим полученный результат:
 \begin{align*}
  \sum_{n=0}^{\infty}\delta^{n}P(\xi_n=0) = \frac{1}{\pi} \int_{0}^{\pi} \frac{dt}{1 - \delta + \delta \cdot o(t)}.
 \end{align*} Существует $ w \in (0, 1) $ такое, что  $ \left|o(t) \right| \leqslant t $  на $ [0,w] $. Тогда
  \begin{align*}
   \sum_{n=0}^{\infty}\delta^{n}P(\xi_n=0) &\geqslant \frac{1}{\pi}\int_{0}^{w} \frac{dt}{1 - \delta + \delta t} = \left. \frac{1}{\pi} \cdot \frac{\log \left| 1 - \delta + \delta t \right|}{\delta} \right|_0^{w} = \\
    &= \frac{\log \left| 1 - \delta + \delta \cdot w \right| - \log \left| 1 - \delta \right|}{\pi \delta}.
 \end{align*} Устремим теперь $ \delta \to 1- $.  Тогда правая часть стремится к $ +\infty $:
 \begin{align*}
  \lim_{\delta \to 1-} \frac{\log \left| 1 - \delta + \delta \cdot w \right| - \log \left| 1 - \delta \right|}{\pi \delta} = \frac{\log \left| w \right|}{\pi} + \lim_{\delta \to 1-}  \log \left| 1 - \delta \right| = +\infty,
 \end{align*} а левая часть стремится к ряду \eqref{eq:symmetrical_random_walk_on_Z:main_series_to_prove}. Следовательно, ряд \eqref{eq:symmetrical_random_walk_on_Z:main_series_to_prove} расходится.
 \end{proof}

 \begin{remrk}
  В таком случайном блуждании все состояния нулевые (кроме случая, когда блуждание не случайно: с вероятностью $ 1 $ мы смещаемся по одному и тому же сдвигу).
 \end{remrk}
 \begin{proof}[\normalfont\textsc{Доказательство}]
  Надо понять, что
  \begin{align*}
   P(\xi_n = 0) &= \frac{1}{2\pi} \int_{-\pi}^{\pi} G(e^{it})^{n}\,dt \to 0
  \end{align*} при $ n \to \infty $. Для этого достаточно доказать, что
  \begin{align*}
   G(e^{it})^{n} \to 0
  \end{align*} при почти всех $ t \in (-\pi, \pi) $.

  Если $ \left| G(e^{it}) \right| < 1 $, то совершенно очевидно $G(e^{it})^{n} \to 0$, поэтому интересен только случай $ \left| G(e^{it}) \right| = 1 $. Мы покажем, что на самом деле множество таких $ t $ имеет нулевую меру.

  Предположим, что $ \left| G(e^{it}) \right|=1 $.
  \begin{align*}
   \left| G(e^{it}) \right| = \left| \sum_{k \in \Z} P(\eta_1 =k) \cdot e^{ikt} \right| \leqslant \sum_{k \in \Z} P(\eta_1 = k) \left| e^{ikt} \right|.
  \end{align*} Равенство в этом неравенстве означает, что все аргументы одинаковы при всех $ k \in \Z $ таких, что $ P(\eta_1 = k) > 0 $. Если такое $ k $ только одно, то мы получаем вырожденный случай, который был обговорён в условии. Иначе есть два таких числа $ k,m\in\Z $, что $ P(\eta_1 = k) > 0 $ и $ P(\eta_1 = m) > 0 $. Тогда для них верно
  \begin{align*}
   \arg e^{ikt} = \arg e^{imt}.
  \end{align*} Равенство аргументов означает
  \begin{align*}
   kt = mt + 2\pi r, \quad r \in\Z.
  \end{align*} Тогда
  \begin{align*}
   t = \frac{2\pi r}{k - m} \in \pi \Q
  \end{align*} таких $ t $ не более чем счётно! Следовательно, мера плохих $ t $ равна нулю.
 \end{proof}

 \subsection{Случайное блуждание по \texorpdfstring{$\Z^{d}$}{Zd}. Теорема Пойа о возвращении.}

 Исследуем теперь случайное блуждание в б\'{о}льших размерностях: пусть теперь мы блуждаем не по прямой, а по $ d $-мерной решётке $ \Z^{d} $, $ d \geqslant 1 $.

 \begin{df*}
  \textit{Случайным блужданием} по $ \Z^{d} $, $ d \geqslant 1 $ называется дискретный случайный процесс, в котором из каждой точки мы можем перейти в одну из $ 2d $ соседних точек с одинаковой вероятностью $ \frac{1}{2d} $.
 \end{df*}

 \begin{thm}[теорема Пойа о возвращении]
  \label{theorem:polya_random_walk_on_Z_d}
  Случайное блуждание по $ \Z^{d} $ возвратно тогда и только тогда, когда $ d=1 $ или $ d=2 $.
 \end{thm}

 Шуточная интерпретация теоремы \ref{theorem:polya_random_walk_on_Z_d}: пьяный муравей, блуждающий по соломинке, почти наверное вернётся назад; пьяный мужик, шатающийся по городу, почти наверное вернётся домой; а пьяная ворона назад не вернётся.

 \begin{proof}[\normalfont\textsc{Доказательство теоремы \ref{theorem:polya_random_walk_on_Z_d}}]\
  \begin{itemize}
   \item Возвратность в случае $ d=1 $ мы уже доказали в теореме \ref{theorem:random_walk_on_Z_d_back}.
   \item Докажем возвратность в случае $ d = 2 $. Пусть $ \vec\xi_n = (x_n, y_n) $ --- точка на шаге $ n $. Повернём плоскость $ \Z^{2} $ на $ 45 $ градусов: рассмотрим два диагональных вектора $ \vec u = (1, 1) $, $ \vec v = (-1, 1) $, и рассмотрим проекции $ u_n, v_n $ точки $ \vec\xi_n $ на вектора $ \vec u $ и $ \vec v $ соответственно (точнее, проекции, домноженные на $ \sqrt 2 $, чтобы было выполнено $ u_n,v_n \in \Z $). См. рисунок \ref{fig:random_walk_on_z2}.

    \begin{figure}[ht]
     \centering
     \incfig{random_walk_on_z2}
     \caption{Случайное блуждание по $ \Z^{2} $ --- это два параллельных независимых случайных блуждания по $ \Z $.}
     \label{fig:random_walk_on_z2}
    \end{figure}

    Утверждается, что случайные величины $ u_n $ и $ v_n $ в отдельности образуют случайное блуждание по $ \Z $, причём для каждого $ n $ величины $ u_n $ и $ v_n $ независимы. В самом деле, на каждом шаге к вектору $ (u_n, v_n) $ с равной вероятностью прибавится один из векторов $ (1,1), (1,-1), (-1, 1), (-1, -1) $, то есть можно сказать, что $ u_{n+1} = u_n + \Delta^{u}_n$ и $ v_{n+1} = v_n + \Delta^{v}_n $, где $ \Delta^{u}_n, \Delta^{v}_n $ независимы и принимают значение $ \pm 1 $ с вероятностью $ 1 / 2 $. Так как изначально $ u_0 = 0 $ и $ v_0 = 0 $ независимы, то по индукции $ u_n $ и $ v_n $ независимы для любого $ n \geqslant 0 $.

    Тогда вероятность вернуться в точку $ \vec 0 $ равна
    \begin{align*}
     p_{\vec 0, \vec 0}(2n + 1) &= 0,\\
     p_{\vec 0, \vec 0}(2n) &= P(\xi_{2n} = \vec 0) = P(u_{2n} = 0,\;v_{2n} = 0) = P(u_{2n} = 0) \cdot P(v_{2n} = 0) = \\
     &= \left( \binom {2n}{n} \cdot \frac{1}{4^{n}} \right)^{2} \sim \left( \frac{1}{\sqrt{\pi n}} \right)^{2} = \frac{1}{\pi n}.
    \end{align*} Значит, ряд этих вероятностей расходится:
    \begin{align*}
     \sum_{n=0}^{\infty}p_{\vec 0, \vec 0}(n) = +\infty,
    \end{align*} и по критерию возвратности (теорема \ref{theorem:back_criteria}) случайное блуждание по $ \Z^{2} $ возвратно.

   \item Докажем невозвратность в случае $ d =3  $. Вычислим вероятность вернуться $ p_{\vec 0, \vec 0}(n) = P(\vec \xi_n = \vec 0) $. Ясно, что для нечётного числа шагов $ P(\vec \xi_{2n+1} = \vec 0) = 0 $. Для чётного числа шагов запишем
    \begin{align*}
     P(\vec\xi_{2n} = \vec 0) = \frac{1}{6^{2n}} \sum_{i+j \leqslant n} \binom{2n}{i,i,j,j,n-i-j,n-i-j}.
    \end{align*} Это верно, так как для каждой из трёх осей нам нужно выбрать одинаковое число шагов в каждом из двух направлений этой оси (здесь $ i $ шагов туда и обратно по первой оси, $ j $ шагов туда и обратно по второй оси, и $ n - i - j $ --- по третьей).

    Перепишем мультиномиальный  коэффициент:
    \begin{align*}
     \binom{2n}{i,i,j,j,n-i-j,n-i-j} &= \frac{(2n)!}{\left( i!j!(n-i-j)! \right)^{2}} = \\
     &= \frac{(2n)!}{(n!)^{2}} \left( \frac{n!}{i! j! (n-i-j)!} \right)^{2} = \\
     &= \binom{2n} n \cdot \binom{n}{i,j,n-i-j}^{2}.
    \end{align*} Подставим обратно в сумму:
    \begin{align*}
     P(\vec\xi_{2n}=\vec0)&= \frac{1}{6^{2n}}\binom{2n}{n} \sum_{i + j \leqslant n} \binom n {i,j,n-i-j}^{2}
    \end{align*} Так как
    \begin{align*}
     \sum_{i+j \leqslant n} \binom{n}{i,j,n-i-j} = 3^{n},
    \end{align*} то сумму квадратов мультиномиальных коэффициентов можно оценить как сумму, умноженную на максимум:
    \begin{align*}
     P(\vec\xi_{2n}=\vec 0) \leqslant \binom{2n}n \frac{3^{n}}{6^{2n}} \max_{i+j \leqslant n} \binom{n}{i,j,n-i-j}.
    \end{align*} Как известно (упражнение \ref{exercise:max_multinom_n_div_3}), максимум мультиномиального коэффициента достигается при $ i $ и $ j $ таких, что $ i = n / 3 + \OO(1) $ и $ j = n / 3 + \OO(1) $. Подставим эти $ i $ и $ j $, и раскроем мультиномиальный коэффициент по формуле Стирлинга:
    \begin{align*}
     \max_{i+j \leqslant n} \binom n {i,j,n-i-j} &= \binom n {\frac{n}{3} + \OO(1),\frac{n}{3} + \OO(1),\frac{n}{3}+\OO(1)} = \frac{n!}{\left(\frac{n}{3} + \OO(1)\right)!} \sim \\
     &\sim \frac{\sqrt{2\pi n}\cdot n^{n} e^{-n}}{\left( \sqrt{2 / 3 \cdot \pi n} \left(\frac{n}{3}\right)^{n / 3} e^{-n / 3} \right)^{3}} = \\
     &= \frac{\sqrt{2\pi n} \cdot n^{n}e^{-n}}{2 / 3 \cdot \pi n \sqrt{2 / 3 \cdot \pi n} \cdot \frac{n^{n}}{3^{n}} \cdot e^{-n}} = \\
     &= 3^{n} \cdot \frac{3\sqrt 3}{2\pi n}.
    \end{align*} Подставим обратно:
    \begin{align*}
     P(\vec\xi_{2n}=\vec 0) &\leqslant \binom{2n}{n} \frac{3^{n}}{6^{2n}} \max_{i+j \leqslant n} \binom n {i,j,n-i-j} \sim \\
     &\sim \frac{4^{n}}{\sqrt{\pi n}} \cdot \frac{3^{n}}{6^{2n}} \cdot 3^{n} \cdot \frac{3 \sqrt 3}{2\pi n} = \OO \left( \frac{1}{n \sqrt n} \right).
    \end{align*} Значит, ряд вероятностей возврата сходится:
    \begin{align*}
     \sum_{n=0}^{\infty} p_{\vec 0, \vec 0}(n) < +\infty.
    \end{align*} По критерию возвратности (теорема \ref{theorem:back_criteria}) случайное блуждание в $ \Z^{3} $ не возвратно!

   \item Сведём случай $ d \geqslant 4 $ к $ d=3 $. При блуждании в $ \Z^{3} $ будем следить за проекцией точки на $ \Z^{3} $. Проекция образует случайное блуждание в $ \Z^{3} $, но с некоторой вероятностью мы стоим. Бесконечно стоять можем лишь с вероятностью $ 0 $, поэтому все стоянки можно выкинуть, и мы получим случайное блуждание на $ \Z^{3} $. А тогда, чтобы вернуться в $ \Z^{d} $, надо как минимум вернуться в $ \Z^{3} $, а вероятность этого уже меньше единицы.
  \end{itemize}
 \end{proof}
 \begin{exercs}
  \label{exercise:max_multinom_n_div_3}
  Доказать, что  максимальность мультиномиального коэффициента
  \begin{align*}
   \binom{n}{i,j,n-i-j} = \max
  \end{align*} влечёт ограничения
  \begin{align*}
   n-j-1 \leqslant &\;2i \leqslant n - j + 1,\\
   n-i-1 \leqslant &\;2j \leqslant n - i + 1.
  \end{align*}

  Если это доказать, то мы получим
  \begin{align}
   \label{eq:max_multinom_n_div_3:2i_plus_j} 2i + j = n + \OO(1),\\
   \label{eq:max_multinom_n_div_3:2j_plus_i} 2j + i = n + \OO(1).
  \end{align} Складывая \eqref{eq:max_multinom_n_div_3:2i_plus_j} и \eqref{eq:max_multinom_n_div_3:2j_plus_i}, получаем
  \begin{align}
   \label{eq:max_multinom_n_div_3:i_plus_j}
   3(i + j) = 2n + \OO(1) \implies i + j = \frac{2n}{3} + \OO(1).
  \end{align} А если вычесть \eqref{eq:max_multinom_n_div_3:2j_plus_i} из \eqref{eq:max_multinom_n_div_3:2i_plus_j}, то получим
  \begin{align}
   \label{eq:max_multinom_n_div_3:i_minus_j}
   i - j = \OO(1).
  \end{align} Из условий \eqref{eq:max_multinom_n_div_3:i_plus_j} и \eqref{eq:max_multinom_n_div_3:i_minus_j} следует
  \begin{align*}
   i = \frac{n}{3} + \OO(1), && j = \frac{n}{3} + \OO(1).
  \end{align*}
 \end{exercs}
 \begin{exercs*}
  Рассмотрим блуждание по $ \Z^{d} $ по векторам вида $ (\pm 1, \ldots, \pm 1) $ равновероятно по $ \frac{1}{2^{d}} $. Доказать, что блуждание возвратно тогда и только тогда, когда $ d = 1 $ или $ d = 2 $.

  Это проще, чем теорема Пойа. Подсказка: ряд $ \sum \frac{1}{n} $ расходится, а ряд $ \sum \frac{1}{n^{3 / 2}} $ сходится!
 \end{exercs*}

 \subsection{Задача о разорении игрока.}

 \begin{exmpl}[задача о разорении игрока]

  Рассмотрим следующую игру. Игрок $ A $ изначально имеет $ A > 0 $ монет, а игрок $ B $ --- $ B > 0 $ монет. Они играют в орлянку с кривой монеткой: каждый раунд с вероятностью $ p \in (0,1) $ игрок $ A $ побеждает раунд, и $ B $ платит ему одну монету, а с вероятностью $ q = 1 - p $ наоборот: $ A $ платит $ B $ одну монетку. Игра заканчивается, когда какой-то из игроков разорился (у него не осталось монет), и тогда он проигрывает. Нас интересует вероятность того, что в игре победит $ A $ (то есть, разорится игрок $ B $).

  Эту игру можно промоделировать так: есть фазовое пространство целых точек от $ -A $ до $ B $ включительно. Расстояние до $ -A $ --- количество монет у игрока $ A $, а расстояние до $ B $ --- количество монет у игрока $ B $. Из каждой внутренней точки $ x \in (-A, B) $ мы можем перейти либо направо с вероятностью $ p $, либо налево с вероятностью $ q $. Из крайних точек $ -A $ и $ B $ мы можем только с вероятностью $ 1 $ перейти в них самих.

  Для $ x \in [-A,B] $ обозначим через $ \beta_k(x) $ вероятность через $ k $ шагов оказаться в $ B $, если на нулевом шаге мы находимся в $ x $.  Для каждой внутренней точки $ x \in (-A,B) $ верно рекуррентное соотношение
  \begin{align*}
   \beta_k(x) = p \beta_{k-1}(x+1) + q \beta_{k-1}(x-1),
  \end{align*} а на концах верно $ \beta_k(-A) = 0 $, $ \beta_k(B) = 1 $. Кроме того, эти вероятности возрастают и ограничены единицей:
  \begin{align*}
   \beta_{k-1}(x) \leqslant \beta_k(x) \leqslant 1,
  \end{align*} потому что если мы после шага $ k-1 $ пришли в $ B $, то оттуда мы уже не уйдём. Поэтому, можно перейти к пределу при $ k \to \infty $:
  \begin{align*}
   \beta(x) := \lim_{k \to \infty} \beta_k(x), \quad -A \leqslant x \leqslant B.
  \end{align*} Для предела тогда будет верно
  \begin{align}
   \label{eq:gambler_ruin:rec_beta}
   \beta(x) = p\beta(x+1) +q\beta(x-1),
  \end{align} а также $ \beta(-A) = 0 $ и $ \beta(B) = 1 $. 

  Найдём общее решение рекуррентного уравнения \eqref{eq:gambler_ruin:rec_beta}. Для этого сначала перепишем его в более стандартный вид:
  \begin{align*}
   \beta(x+1) - \frac{\beta(x)}{p} + \frac{q\beta(x-1)}{p} = 0.
  \end{align*} Характеристический многочлен этого уравнения имеет вид
  \begin{align*}
   \lambda^{2} - \frac{\lambda}{p} + \frac{q}{p}.
  \end{align*} Найдём его корни. Дискриминант равен
  \begin{align*}
   D &= b^{2} - 4ac = \frac{1}{p^{2}} - \frac{4q}{p} = \frac{1-4pq}{p^{2}} = \frac{1 - 4p + 4p^{2}}{p^{2}} = \frac{4(p^{2} - p + \frac{1}{4})}{p^{2}} = \frac{4(p - \frac{1}{2})^{2}}{p^{2}}.
  \end{align*} Тогда корни многочлена имеют вид
  \begin{align*}
   \lambda = \frac{\frac{1}{p} \pm \sqrt{ \frac{4(p - \frac{1}{2})^{2}}{p^{2}} }}{2} = \frac{1 \pm 2(p - \frac{1}{2})}{2p} = \frac{1 \pm (2p - 1)}{2p}.
  \end{align*} Первый корень равен
  \begin{align*}
   \lambda_1 = \frac{1 + (2p - 1)}{2p} = 1,
  \end{align*} а второй корень равен
  \begin{align*}
   \lambda_2 = \frac{1 - (2p - 1)}{2p} = \frac{q}{p}.
  \end{align*}

  \begin{itemize}
   \item Рассмотрим сначала случай, когда корни различные, то есть $ p \neq q $. Тогда общее решение имеет вид
    \begin{align*}
     \beta(x) = C_1 + C_2 (q / p)^{x}.
    \end{align*} Теперь подберём параметры. Так как $ \beta(-A) = 0 $, то
    \begin{align}
     \label{eq:gambler_ruin:linrec_C1}
     C_1 + C_2 (q / p)^{-A} = 0 \implies C_1 = -C_2 (q / p)^{-A}.
    \end{align} Так как $ \beta(B) = 1 $, то
    \begin{align*}
     C_1 + C_2 (q / p)^{B} = 1.
    \end{align*} Подставим \eqref{eq:gambler_ruin:linrec_C1}:
    \begin{align*}
     C_2 \left( (q/ p)^{B} - (q / p)^{-A} \right) = 1 \implies C_2 = \frac{1}{(q / p)^{B} - (q / p)^{-A}}.
    \end{align*} Итого,
    \begin{align*}
     \beta(x) = \frac{(q / p)^{x} - (q / p)^{-A}}{(q / p)^{B} - (q / p)^{-A}}.
    \end{align*}
   \item Если же $ p = q = 1 / 2 $, то корни характеристического многочлена совпадают:  $ \lambda_1 = \lambda_2 = 1 $. В этом случае общее решение рекуррентного уравнения имеет вид
    \begin{align*}
     \beta(x) = C_1 + x C_2.
    \end{align*} Подберём параметры:
    \begin{align*}
     &\beta(-A) = C_1 - A C_2 = 0 \implies C_1 = A C_2,\\
     &\beta(B) = C_1 + B C_2 = 1 \implies A C_2 + B C_2 = 1 \implies C_2 = \frac{1}{A + B} \implies \\
     \implies \;&C_1 = \frac{A}{A + B}.
    \end{align*} Итого,
    \begin{align*}
     \beta(x) = \frac{x + A}{A + B}.
    \end{align*}
  \end{itemize}

  Ответ на задачу равен $ \beta(0) $, то есть
  \begin{align*}
   \beta(0) = \frac{1 - (q / p)^{-A}}{(q / p)^{B} - (q / p)^{-A}}
  \end{align*} в случае $ p \neq q $, и
  \begin{align*}
   \beta(0) = \frac{A}{A + B}
  \end{align*} в случае $ p = q = 1 / 2 $.

 \end{exmpl}

 Интересно: матожидание числа раундов до конца игры большое (примерно квадратично по количеству монет, если число монет примерно одинаковое).

 \end{document}

